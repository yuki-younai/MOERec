loadding data
reading category information





100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 136710/136710 [00:12<00:00, 10601.49it/s]
reading train data


100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2571752/2571752 [00:05<00:00, 505471.43it/s]
reading valid data
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 845781/845781 [00:01<00:00, 467592.76it/s]
reading test data
model already setting
get weight for each sample
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 136710/136710 [00:00<00:00, 2495824.94it/s]
train loss = 0.3392277657985687
loss: 0.3795247972011566, Performance is better... saving the model
train loss = 0.30347776412963867
loss: 0.35375410318374634, Performance is better... saving the model
train loss = 0.27119868993759155
Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
loss: 0.33303678035736084, Performance is better... saving the model
train loss = 0.2472190409898758
loss: 0.3195174038410187, Performance is better... saving the model
train loss = 0.23001576960086823
loss: 0.3061930537223816, Performance is better... saving the model
train loss = 0.21591487526893616
loss: 0.2955894470214844, Performance is better... saving the model
train loss = 0.20387931168079376
loss: 0.28688549995422363, Performance is better... saving the model
train loss = 0.1938004344701767
loss: 0.2763136625289917, Performance is better... saving the model
train loss = 0.18527710437774658
loss: 0.26984333992004395, Performance is better... saving the model
train loss = 0.17743034660816193
loss: 0.2619408667087555, Performance is better... saving the model
train loss = 0.17086485028266907
loss: 0.2544480264186859, Performance is better... saving the model
train loss = 0.16513262689113617
loss: 0.2483934462070465, Performance is better... saving the model
train loss = 0.15969687700271606
loss: 0.24226154386997223, Performance is better... saving the model
train loss = 0.15498878061771393
loss: 0.23683395981788635, Performance is better... saving the model
train loss = 0.1508738398551941
loss: 0.23146212100982666, Performance is better... saving the model
train loss = 0.14701513946056366
loss: 0.2275061458349228, Performance is better... saving the model
train loss = 0.14359663426876068
loss: 0.2236376404762268, Performance is better... saving the model
train loss = 0.14036421477794647
loss: 0.21947310864925385, Performance is better... saving the model
train loss = 0.13746201992034912
loss: 0.21595817804336548, Performance is better... saving the model
train loss = 0.13481232523918152
loss: 0.2121613323688507, Performance is better... saving the model
train loss = 0.13233983516693115
loss: 0.20918338000774384, Performance is better... saving the model
train loss = 0.12998154759407043
loss: 0.20674322545528412, Performance is better... saving the model
train loss = 0.12784340977668762
loss: 0.2045479267835617, Performance is better... saving the model
train loss = 0.12579968571662903
loss: 0.20208030939102173, Performance is better... saving the model
train loss = 0.12392832338809967
loss: 0.2002052515745163, Performance is better... saving the model
train loss = 0.12209832668304443
loss: 0.198213130235672, Performance is better... saving the model
train loss = 0.12034480273723602
loss: 0.19641752541065216, Performance is better... saving the model
train loss = 0.118684783577919
loss: 0.1948605179786682, Performance is better... saving the model
train loss = 0.11706148833036423
loss: 0.1929631382226944, Performance is better... saving the model
train loss = 0.11550113558769226
loss: 0.1914825588464737, Performance is better... saving the model
train loss = 0.11380759626626968
loss: 0.1900162398815155, Performance is better... saving the model
train loss = 0.11221776157617569
loss: 0.18851397931575775, Performance is better... saving the model
train loss = 0.11062247306108475
loss: 0.1872766762971878, Performance is better... saving the model
train loss = 0.10896497219800949
loss: 0.18542596697807312, Performance is better... saving the model
train loss = 0.10741627961397171
loss: 0.18409308791160583, Performance is better... saving the model
train loss = 0.10577363520860672
loss: 0.1826755851507187, Performance is better... saving the model
train loss = 0.10402899980545044
loss: 0.18127642571926117, Performance is better... saving the model
train loss = 0.10234607011079788
loss: 0.17967431247234344, Performance is better... saving the model
train loss = 0.10062190890312195
loss: 0.17799288034439087, Performance is better... saving the model
train loss = 0.09889455139636993
loss: 0.17672687768936157, Performance is better... saving the model
train loss = 0.0970553383231163
loss: 0.17524757981300354, Performance is better... saving the model
train loss = 0.09520428627729416
loss: 0.17368517816066742, Performance is better... saving the model
train loss = 0.09335295110940933
loss: 0.1719927340745926, Performance is better... saving the model
train loss = 0.09155670553445816
loss: 0.17051632702350616, Performance is better... saving the model
train loss = 0.08967139571905136
loss: 0.1691192090511322, Performance is better... saving the model
train loss = 0.08783701062202454
loss: 0.16750700771808624, Performance is better... saving the model
train loss = 0.0859447792172432
loss: 0.16575829684734344, Performance is better... saving the model
train loss = 0.08406371623277664
loss: 0.164199560880661, Performance is better... saving the model
train loss = 0.08226070553064346
loss: 0.1624111831188202, Performance is better... saving the model
train loss = 0.08043031394481659
  2%|█████                                                                                                                                                                                                        | 1/41 [00:50<33:22, 50.06s/it]
Traceback (most recent call last):
  File "main.py", line 92, in <module>
    res,ndcg5_std,ndcg10_std,mrr_std,auc_std=tester.test()
  File "/home/gwy/BaseSAT/BaseGAT/utils/tester.py", line 89, in test
    scores = self.model.get_score(h, users)
  File "/home/gwy/BaseSAT/BaseGAT/models/models.py", line 84, in get_score
    scores = torch.mm(user_embed, item_embed.t())
torch.cuda.OutOfMemoryError: CUDA out of memory. Tried to allocate 1.04 GiB (GPU 0; 9.78 GiB total capacity; 2.73 GiB already allocated; 791.31 MiB free; 3.07 GiB reserved in total by PyTorch) If reserved memory is >> allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF