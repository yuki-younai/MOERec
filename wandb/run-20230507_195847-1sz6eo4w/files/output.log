loadding data
reading category information













100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 136710/136710 [00:30<00:00, 4509.38it/s]
reading train data




100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2571752/2571752 [00:08<00:00, 287107.29it/s]
reading valid data
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 845781/845781 [00:02<00:00, 289405.13it/s]
reading test data
get weight for each sample
100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 136710/136710 [00:00<00:00, 1144056.29it/s]
Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
train loss = 0.3392277657985687
loss: 0.3795250356197357, Performance is better... saving the model
train loss = 0.3034779727458954
loss: 0.3537858724594116, Performance is better... saving the model
train loss = 0.27119702100753784
loss: 0.3330456018447876, Performance is better... saving the model
train loss = 0.2472180873155594
loss: 0.3194866478443146, Performance is better... saving the model
train loss = 0.22999677062034607
loss: 0.30618736147880554, Performance is better... saving the model
train loss = 0.215900257229805
loss: 0.2955716550350189, Performance is better... saving the model
train loss = 0.20384085178375244
loss: 0.2868705093860626, Performance is better... saving the model
train loss = 0.19378532469272614
loss: 0.27626070380210876, Performance is better... saving the model
train loss = 0.1852622628211975
loss: 0.2698477506637573, Performance is better... saving the model
train loss = 0.177421435713768
loss: 0.2618970274925232, Performance is better... saving the model
train loss = 0.17084936797618866
loss: 0.25446707010269165, Performance is better... saving the model
train loss = 0.16511137783527374
loss: 0.24841299653053284, Performance is better... saving the model
train loss = 0.15969133377075195
loss: 0.24232372641563416, Performance is better... saving the model
train loss = 0.15500140190124512
loss: 0.23686113953590393, Performance is better... saving the model
train loss = 0.15086029469966888
loss: 0.23147517442703247, Performance is better... saving the model
train loss = 0.147007554769516
loss: 0.2275143265724182, Performance is better... saving the model
train loss = 0.14358559250831604
loss: 0.22363747656345367, Performance is better... saving the model
train loss = 0.1403418332338333
loss: 0.2194938212633133, Performance is better... saving the model
train loss = 0.13745371997356415
loss: 0.21593879163265228, Performance is better... saving the model
train loss = 0.13478729128837585
loss: 0.21215422451496124, Performance is better... saving the model
train loss = 0.13230814039707184
loss: 0.2091822773218155, Performance is better... saving the model
train loss = 0.12995323538780212
loss: 0.20678265392780304, Performance is better... saving the model
train loss = 0.12780854105949402
loss: 0.2045765221118927, Performance is better... saving the model
train loss = 0.12576790153980255
loss: 0.20212841033935547, Performance is better... saving the model
train loss = 0.12389804422855377
loss: 0.20025543868541718, Performance is better... saving the model
train loss = 0.12206462770700455
loss: 0.1982032060623169, Performance is better... saving the model
train loss = 0.12030889093875885
loss: 0.19636812806129456, Performance is better... saving the model
train loss = 0.11864552646875381
loss: 0.1948859989643097, Performance is better... saving the model
train loss = 0.11703132838010788
loss: 0.19297412037849426, Performance is better... saving the model
train loss = 0.11546783894300461
loss: 0.19147339463233948, Performance is better... saving the model
train loss = 0.11378292739391327
loss: 0.18998582661151886, Performance is better... saving the model
train loss = 0.11219525337219238
loss: 0.18850035965442657, Performance is better... saving the model
train loss = 0.11058603972196579
loss: 0.18719454109668732, Performance is better... saving the model
train loss = 0.10893106460571289
loss: 0.1854122132062912, Performance is better... saving the model
train loss = 0.10738851875066757
loss: 0.18403968214988708, Performance is better... saving the model
train loss = 0.10574643313884735
loss: 0.18260861933231354, Performance is better... saving the model
train loss = 0.10400093346834183
loss: 0.18124271929264069, Performance is better... saving the model
train loss = 0.10231192409992218
loss: 0.17961259186267853, Performance is better... saving the model
train loss = 0.1005869209766388
loss: 0.17793214321136475, Performance is better... saving the model
train loss = 0.09885354340076447
loss: 0.17668916285037994, Performance is better... saving the model
train loss = 0.0970102846622467
loss: 0.17517347633838654, Performance is better... saving the model
train loss = 0.09516040235757828
loss: 0.17361608147621155, Performance is better... saving the model
train loss = 0.09331220388412476
loss: 0.17193379998207092, Performance is better... saving the model
train loss = 0.09149948507547379
loss: 0.17041848599910736, Performance is better... saving the model
train loss = 0.0896172970533371
loss: 0.1690385639667511, Performance is better... saving the model
train loss = 0.0877746045589447
loss: 0.1673922836780548, Performance is better... saving the model
train loss = 0.0858815535902977
loss: 0.16565266251564026, Performance is better... saving the model
train loss = 0.08400258421897888
loss: 0.16413652896881104, Performance is better... saving the model
train loss = 0.0821998342871666
loss: 0.16233815252780914, Performance is better... saving the model
train loss = 0.08037775754928589
loss: 0.16045351326465607, Performance is better... saving the model
train loss = 0.07862192392349243
loss: 0.15907476842403412, Performance is better... saving the model
train loss = 0.07693158090114594
loss: 0.15752846002578735, Performance is better... saving the model
train loss = 0.0752510204911232
loss: 0.1558132767677307, Performance is better... saving the model
train loss = 0.07364130020141602
loss: 0.1542338877916336, Performance is better... saving the model
train loss = 0.0721072182059288
loss: 0.15236276388168335, Performance is better... saving the model
train loss = 0.07061780989170074
loss: 0.15130797028541565, Performance is better... saving the model
train loss = 0.0691932737827301
loss: 0.14977331459522247, Performance is better... saving the model
train loss = 0.06785660237073898
loss: 0.14800870418548584, Performance is better... saving the model
train loss = 0.06654025614261627
loss: 0.1469479501247406, Performance is better... saving the model
train loss = 0.06533633917570114
loss: 0.14532063901424408, Performance is better... saving the model
train loss = 0.06418102234601974
loss: 0.14410126209259033, Performance is better... saving the model
train loss = 0.06308306008577347
loss: 0.14314234256744385, Performance is better... saving the model
train loss = 0.06212202087044716
loss: 0.1420212984085083, Performance is better... saving the model
train loss = 0.06114187836647034
loss: 0.14076799154281616, Performance is better... saving the model
train loss = 0.06029525771737099
loss: 0.13959884643554688, Performance is better... saving the model
train loss = 0.059435971081256866
loss: 0.138583242893219, Performance is better... saving the model
train loss = 0.058699604123830795
loss: 0.13769836723804474, Performance is better... saving the model
train loss = 0.05799368768930435
loss: 0.13665342330932617, Performance is better... saving the model
train loss = 0.05726223066449165
loss: 0.13574613630771637, Performance is better... saving the model
train loss = 0.05664638429880142
loss: 0.13475772738456726, Performance is better... saving the model
train loss = 0.05612873286008835
loss: 0.1337418556213379, Performance is better... saving the model
train loss = 0.05559196323156357
loss: 0.13309934735298157, Performance is better... saving the model
train loss = 0.055087827146053314
loss: 0.13231144845485687, Performance is better... saving the model
train loss = 0.054595399647951126
loss: 0.1313886195421219, Performance is better... saving the model
train loss = 0.054173391312360764
loss: 0.13088209927082062, Performance is better... saving the model
train loss = 0.053789641708135605
loss: 0.12980373203754425, Performance is better... saving the model
train loss = 0.05340871959924698
loss: 0.12947113811969757, Performance is better... saving the model
train loss = 0.05307300388813019
loss: 0.12875233590602875, Performance is better... saving the model
train loss = 0.05273459106683731
loss: 0.1280858814716339, Performance is better... saving the model
train loss = 0.05246599763631821
loss: 0.12747912108898163, Performance is better... saving the model
train loss = 0.052166663110256195
loss: 0.12711447477340698, Performance is better... saving the model
train loss = 0.051860250532627106
loss: 0.12647873163223267, Performance is better... saving the model
train loss = 0.051584672182798386
loss: 0.12553107738494873, Performance is better... saving the model
train loss = 0.0513216070830822
loss: 0.12509334087371826, Performance is better... saving the model
train loss = 0.05108384042978287
loss: 0.12453175336122513, Performance is better... saving the model
train loss = 0.050828661769628525
loss: 0.12403478473424911, Performance is better... saving the model
train loss = 0.05061471089720726
loss: 0.12363524734973907, Performance is better... saving the model
train loss = 0.05033566802740097
loss: 0.12331139296293259, Performance is better... saving the model
train loss = 0.05016693100333214
loss: 0.12289609760046005, Performance is better... saving the model
train loss = 0.049958840012550354
loss: 0.12229406833648682, Performance is better... saving the model
train loss = 0.04969712719321251
loss: 0.1219308078289032, Performance is better... saving the model
train loss = 0.049488767981529236
loss: 0.1215999573469162, Performance is better... saving the model
train loss = 0.04929422214627266
loss: 0.12117297947406769, Performance is better... saving the model
train loss = 0.049077678471803665
loss: 0.12072519212961197, Performance is better... saving the model
train loss = 0.048887673765420914
loss: 0.12053127586841583, Performance is better... saving the model
train loss = 0.04868751019239426
loss: 0.12020356208086014, Performance is better... saving the model
train loss = 0.048523541539907455
loss: 0.11962883174419403, Performance is better... saving the model
train loss = 0.04832465574145317
loss: 0.11921963095664978, Performance is better... saving the model
train loss = 0.04811941087245941
loss: 0.11928608268499374, EarlyStopping counter: 1 out of 10
train loss = 0.04798468202352524









































100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [19:45<00:00, 28.90s/it]
For top100, metric recall = 0.03593405541548149
For top300, metric recall = 0.07342493466827496
For top100, metric hit_ratio = 0.2483632447085305
For top300, metric hit_ratio = 0.41082860358452433
For top100, metric coverage = 45.06406641414447
For top300, metric coverage = 104.2895332373265
loss: 0.11857161670923233, Performance is better... saving the model
train loss = 0.04781082645058632
loss: 0.11820121109485626, Performance is better... saving the model
train loss = 0.04764232411980629
loss: 0.1183386892080307, EarlyStopping counter: 1 out of 10
train loss = 0.0474541001021862
loss: 0.11788556724786758, Performance is better... saving the model
train loss = 0.047339726239442825
loss: 0.11760719120502472, Performance is better... saving the model
train loss = 0.047181226313114166
loss: 0.11715111136436462, Performance is better... saving the model
train loss = 0.04700383543968201
loss: 0.11692430078983307, Performance is better... saving the model
train loss = 0.046855248510837555
loss: 0.11685660481452942, Performance is better... saving the model
train loss = 0.046723295003175735
loss: 0.11651162058115005, Performance is better... saving the model
train loss = 0.046632442623376846
loss: 0.1160900816321373, Performance is better... saving the model
train loss = 0.0464676171541214
loss: 0.1163182482123375, EarlyStopping counter: 1 out of 10
train loss = 0.04636672884225845
loss: 0.1160351112484932, Performance is better... saving the model
train loss = 0.04626771807670593
loss: 0.11586038768291473, Performance is better... saving the model
train loss = 0.04608645290136337
loss: 0.1154276579618454, Performance is better... saving the model
train loss = 0.045977603644132614
loss: 0.11539852619171143, Performance is better... saving the model
train loss = 0.04586843401193619
loss: 0.1153595894575119, Performance is better... saving the model
train loss = 0.045741233974695206
loss: 0.11495883762836456, Performance is better... saving the model
train loss = 0.04562638700008392
loss: 0.11472679674625397, Performance is better... saving the model
train loss = 0.04554830491542816
loss: 0.11466993391513824, Performance is better... saving the model
train loss = 0.04540640860795975
loss: 0.11447690427303314, Performance is better... saving the model
train loss = 0.04533056169748306
loss: 0.11459306627511978, EarlyStopping counter: 1 out of 10
train loss = 0.045191287994384766
loss: 0.11401338130235672, Performance is better... saving the model
train loss = 0.04509482905268669
loss: 0.11416497826576233, EarlyStopping counter: 1 out of 10
train loss = 0.04499003663659096
loss: 0.11404810100793839, EarlyStopping counter: 2 out of 10
train loss = 0.04487890377640724
loss: 0.1135937049984932, Performance is better... saving the model
train loss = 0.044805243611335754
loss: 0.11364889144897461, EarlyStopping counter: 1 out of 10
train loss = 0.044714078307151794
loss: 0.11366002261638641, EarlyStopping counter: 2 out of 10
train loss = 0.04463028907775879
loss: 0.11346855759620667, Performance is better... saving the model
train loss = 0.044539690017700195
loss: 0.11323759704828262, Performance is better... saving the model
train loss = 0.0444229394197464
loss: 0.11294616013765335, Performance is better... saving the model
train loss = 0.044341303408145905
loss: 0.11313250660896301, EarlyStopping counter: 1 out of 10
train loss = 0.044277623295784
loss: 0.1126062348484993, Performance is better... saving the model
train loss = 0.04416828230023384
loss: 0.1127951443195343, EarlyStopping counter: 1 out of 10
train loss = 0.044044967740774155
loss: 0.11250000447034836, Performance is better... saving the model
train loss = 0.04399682208895683
loss: 0.11229894310235977, Performance is better... saving the model
train loss = 0.043947990983724594
loss: 0.11247135698795319, EarlyStopping counter: 1 out of 10
train loss = 0.043823592364788055
loss: 0.11227211356163025, Performance is better... saving the model
train loss = 0.04377388209104538
loss: 0.11215782910585403, Performance is better... saving the model
train loss = 0.04366135224699974
loss: 0.11222783476114273, EarlyStopping counter: 1 out of 10
train loss = 0.04360589385032654
loss: 0.11177448183298111, Performance is better... saving the model
train loss = 0.04355264827609062
loss: 0.11164496093988419, Performance is better... saving the model
train loss = 0.04344094544649124
loss: 0.11187244951725006, EarlyStopping counter: 1 out of 10
train loss = 0.043373316526412964
loss: 0.11165598034858704, EarlyStopping counter: 2 out of 10
train loss = 0.04330457001924515
loss: 0.11141933500766754, Performance is better... saving the model
train loss = 0.04320523142814636
loss: 0.11160998046398163, EarlyStopping counter: 1 out of 10
train loss = 0.04314946010708809
loss: 0.1117190271615982, EarlyStopping counter: 2 out of 10
train loss = 0.043063804507255554
loss: 0.11151657998561859, EarlyStopping counter: 3 out of 10
train loss = 0.04298583045601845
loss: 0.111390620470047, Performance is better... saving the model
train loss = 0.042947474867105484
loss: 0.11128146946430206, Performance is better... saving the model
train loss = 0.04285138100385666
loss: 0.11115386337041855, Performance is better... saving the model
train loss = 0.042820390313863754
loss: 0.11086700111627579, Performance is better... saving the model
train loss = 0.04270666837692261
loss: 0.11098890751600266, EarlyStopping counter: 1 out of 10
train loss = 0.04265572875738144
loss: 0.11100489646196365, EarlyStopping counter: 2 out of 10
train loss = 0.04257466644048691
loss: 0.11103475093841553, EarlyStopping counter: 3 out of 10
train loss = 0.042531818151474
loss: 0.11094530671834946, EarlyStopping counter: 4 out of 10
train loss = 0.04246746748685837
loss: 0.11057036370038986, Performance is better... saving the model
train loss = 0.0424235463142395
loss: 0.11052781343460083, Performance is better... saving the model
train loss = 0.042314525693655014
loss: 0.11046330630779266, Performance is better... saving the model
train loss = 0.04228326678276062
loss: 0.11036156862974167, Performance is better... saving the model
train loss = 0.0422375462949276
loss: 0.11047934740781784, EarlyStopping counter: 1 out of 10
train loss = 0.04215821996331215
loss: 0.1106121689081192, EarlyStopping counter: 2 out of 10
train loss = 0.04209878668189049
loss: 0.11026650667190552, Performance is better... saving the model
train loss = 0.042082227766513824
loss: 0.11049413681030273, EarlyStopping counter: 1 out of 10
train loss = 0.041977252811193466
loss: 0.11016888171434402, Performance is better... saving the model
train loss = 0.041944630444049835
loss: 0.10993295907974243, Performance is better... saving the model
train loss = 0.041922278702259064
loss: 0.10991931706666946, Performance is better... saving the model
train loss = 0.04182632267475128
loss: 0.10991495847702026, Performance is better... saving the model
train loss = 0.04179587960243225
loss: 0.1099335253238678, EarlyStopping counter: 1 out of 10
train loss = 0.04172324016690254
loss: 0.10994983464479446, EarlyStopping counter: 2 out of 10
train loss = 0.04167620837688446
loss: 0.10987939685583115, Performance is better... saving the model
train loss = 0.04161440208554268
loss: 0.10973598062992096, Performance is better... saving the model
train loss = 0.04154861718416214
loss: 0.10952170193195343, Performance is better... saving the model
train loss = 0.041468728333711624
loss: 0.10933233797550201, Performance is better... saving the model
train loss = 0.04144557937979698
loss: 0.10955091565847397, EarlyStopping counter: 1 out of 10
train loss = 0.04139398783445358
loss: 0.1096496507525444, EarlyStopping counter: 2 out of 10
train loss = 0.0413503423333168
loss: 0.10921495407819748, Performance is better... saving the model
train loss = 0.041296083480119705
loss: 0.10936477780342102, EarlyStopping counter: 1 out of 10
train loss = 0.04118889197707176
loss: 0.10939357429742813, EarlyStopping counter: 2 out of 10
train loss = 0.04121401906013489
loss: 0.10910569876432419, Performance is better... saving the model
train loss = 0.04112018644809723
loss: 0.10942742973566055, EarlyStopping counter: 1 out of 10
train loss = 0.041086044162511826
loss: 0.10903363674879074, Performance is better... saving the model
train loss = 0.04105227440595627
loss: 0.10892976075410843, Performance is better... saving the model
train loss = 0.041001006960868835
loss: 0.10920482128858566, EarlyStopping counter: 1 out of 10
train loss = 0.04092321917414665
loss: 0.10918226093053818, EarlyStopping counter: 2 out of 10
train loss = 0.040909089148044586
loss: 0.10897774249315262, EarlyStopping counter: 3 out of 10
train loss = 0.04085392877459526
loss: 0.10895625501871109, EarlyStopping counter: 4 out of 10
train loss = 0.04079838842153549
loss: 0.10905153304338455, EarlyStopping counter: 5 out of 10
train loss = 0.04071355611085892
loss: 0.10911589860916138, EarlyStopping counter: 6 out of 10
train loss = 0.04070477932691574
loss: 0.10887008160352707, Performance is better... saving the model
train loss = 0.040621139109134674
loss: 0.1088537722826004, Performance is better... saving the model
train loss = 0.04060104861855507
loss: 0.10867595672607422, Performance is better... saving the model
train loss = 0.04055408015847206
loss: 0.10862624645233154, Performance is better... saving the model
train loss = 0.040504906326532364
loss: 0.10856280475854874, Performance is better... saving the model
train loss = 0.04044824093580246
loss: 0.10863751173019409, EarlyStopping counter: 1 out of 10
train loss = 0.04041457176208496
loss: 0.10853645205497742, Performance is better... saving the model
train loss = 0.040412597358226776
loss: 0.10858976095914841, EarlyStopping counter: 1 out of 10
train loss = 0.040338896214962006
loss: 0.10868343710899353, EarlyStopping counter: 2 out of 10
train loss = 0.04028197377920151
loss: 0.10851733386516571, Performance is better... saving the model
train loss = 0.040249381214380264
loss: 0.10842692852020264, Performance is better... saving the model
train loss = 0.04018942639231682
loss: 0.10803160816431046, Performance is better... saving the model
train loss = 0.04018063843250275









































100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [19:48<00:00, 28.98s/it]
For top100, metric recall = 0.04404507006904668
For top300, metric recall = 0.08892000485494815
For top100, metric hit_ratio = 0.28799632108237627
For top300, metric hit_ratio = 0.46299904396548597
For top100, metric coverage = 40.58695678481963
For top300, metric coverage = 92.7104667626735
loss: 0.1082373559474945, EarlyStopping counter: 1 out of 10
train loss = 0.040106937289237976
loss: 0.10820617526769638, EarlyStopping counter: 2 out of 10
train loss = 0.04008709639310837
loss: 0.108206607401371, EarlyStopping counter: 3 out of 10
train loss = 0.04002997279167175
loss: 0.1081906110048294, EarlyStopping counter: 4 out of 10
train loss = 0.04002253711223602
loss: 0.10846779495477676, EarlyStopping counter: 5 out of 10
train loss = 0.03994821012020111
loss: 0.10804034769535065, EarlyStopping counter: 6 out of 10
train loss = 0.03992369771003723
loss: 0.10821285843849182, EarlyStopping counter: 7 out of 10
train loss = 0.03989148139953613
loss: 0.1079573929309845, Performance is better... saving the model
train loss = 0.03985128179192543
loss: 0.10802621394395828, EarlyStopping counter: 1 out of 10
train loss = 0.03982680290937424
loss: 0.1082041785120964, EarlyStopping counter: 2 out of 10
train loss = 0.03974338620901108
loss: 0.10785572975873947, Performance is better... saving the model
train loss = 0.03969530016183853
loss: 0.1081194281578064, EarlyStopping counter: 1 out of 10
train loss = 0.03969766944646835
loss: 0.10799799114465714, EarlyStopping counter: 2 out of 10
train loss = 0.039655592292547226
loss: 0.10759557783603668, Performance is better... saving the model
train loss = 0.03963030129671097
loss: 0.10782922059297562, EarlyStopping counter: 1 out of 10
train loss = 0.03958236798644066
loss: 0.10799206793308258, EarlyStopping counter: 2 out of 10
train loss = 0.03954008221626282
loss: 0.10789025574922562, EarlyStopping counter: 3 out of 10
train loss = 0.03951221704483032
loss: 0.10790331661701202, EarlyStopping counter: 4 out of 10
train loss = 0.03946257382631302
loss: 0.1076725423336029, EarlyStopping counter: 5 out of 10
train loss = 0.03945493698120117
loss: 0.1076541543006897, EarlyStopping counter: 6 out of 10
train loss = 0.039413921535015106
loss: 0.10759886354207993, EarlyStopping counter: 7 out of 10
train loss = 0.03936430439352989
loss: 0.10755319893360138, Performance is better... saving the model
train loss = 0.0393485426902771
loss: 0.10772302001714706, EarlyStopping counter: 1 out of 10
train loss = 0.03930194303393364
loss: 0.10766874998807907, EarlyStopping counter: 2 out of 10
train loss = 0.03925229236483574
loss: 0.10753382742404938, Performance is better... saving the model
train loss = 0.03921128809452057
loss: 0.10775937139987946, EarlyStopping counter: 1 out of 10
train loss = 0.039231717586517334
loss: 0.10760959982872009, EarlyStopping counter: 2 out of 10
train loss = 0.03914985805749893
loss: 0.10740931332111359, Performance is better... saving the model
train loss = 0.039160534739494324
loss: 0.10747705399990082, EarlyStopping counter: 1 out of 10
train loss = 0.03909178823232651
loss: 0.10732723772525787, Performance is better... saving the model
train loss = 0.03906019404530525
loss: 0.10751068592071533, EarlyStopping counter: 1 out of 10
train loss = 0.03906407952308655
loss: 0.10735342651605606, EarlyStopping counter: 2 out of 10
train loss = 0.039006613194942474
loss: 0.10705631971359253, Performance is better... saving the model
train loss = 0.03897993266582489
loss: 0.1070515364408493, Performance is better... saving the model
train loss = 0.038933273404836655
loss: 0.10692861676216125, Performance is better... saving the model
train loss = 0.03893798962235451
loss: 0.10703086107969284, EarlyStopping counter: 1 out of 10
train loss = 0.03887191787362099
loss: 0.1072467491030693, EarlyStopping counter: 2 out of 10
train loss = 0.03883667290210724
loss: 0.10721613466739655, EarlyStopping counter: 3 out of 10
train loss = 0.038799531757831573
loss: 0.10709445178508759, EarlyStopping counter: 4 out of 10
train loss = 0.038782455027103424
loss: 0.10700956732034683, EarlyStopping counter: 5 out of 10
train loss = 0.038756079971790314
loss: 0.10693521052598953, EarlyStopping counter: 6 out of 10
train loss = 0.03871569782495499
loss: 0.10707274079322815, EarlyStopping counter: 7 out of 10
train loss = 0.03867519646883011
loss: 0.10720627009868622, EarlyStopping counter: 8 out of 10
train loss = 0.0386335551738739
loss: 0.10711991041898727, EarlyStopping counter: 9 out of 10
train loss = 0.038604117929935455
loss: 0.10688693076372147, Performance is better... saving the model
train loss = 0.03860560059547424
loss: 0.1066870167851448, Performance is better... saving the model
train loss = 0.038588747382164
loss: 0.10703706741333008, EarlyStopping counter: 1 out of 10
train loss = 0.03855873644351959
loss: 0.10671635717153549, EarlyStopping counter: 2 out of 10
train loss = 0.03850957006216049
loss: 0.10686515271663666, EarlyStopping counter: 3 out of 10
train loss = 0.03846459090709686
loss: 0.1069338247179985, EarlyStopping counter: 4 out of 10
train loss = 0.038438983261585236
loss: 0.106543630361557, Performance is better... saving the model
train loss = 0.038419321179389954
loss: 0.10667222738265991, EarlyStopping counter: 1 out of 10
train loss = 0.03839944675564766
loss: 0.10694363713264465, EarlyStopping counter: 2 out of 10
train loss = 0.03837020695209503
loss: 0.10684116184711456, EarlyStopping counter: 3 out of 10
train loss = 0.03832678869366646
loss: 0.1068049818277359, EarlyStopping counter: 4 out of 10
train loss = 0.03830420598387718
loss: 0.10666708648204803, EarlyStopping counter: 5 out of 10
train loss = 0.038247622549533844
loss: 0.10669757425785065, EarlyStopping counter: 6 out of 10
train loss = 0.0382496602833271
loss: 0.10652080178260803, Performance is better... saving the model
train loss = 0.038238756358623505
loss: 0.10666418075561523, EarlyStopping counter: 1 out of 10
train loss = 0.038194961845874786
loss: 0.10649328678846359, Performance is better... saving the model
train loss = 0.03813847899436951
loss: 0.10648343712091446, Performance is better... saving the model
train loss = 0.03810928016901016
loss: 0.10656806081533432, EarlyStopping counter: 1 out of 10
train loss = 0.03811896592378616
loss: 0.10650359094142914, EarlyStopping counter: 2 out of 10
train loss = 0.0380900502204895
loss: 0.10647950321435928, Performance is better... saving the model
train loss = 0.038034096360206604
loss: 0.1066993847489357, EarlyStopping counter: 1 out of 10
train loss = 0.038019903004169464
loss: 0.10653307288885117, EarlyStopping counter: 2 out of 10
train loss = 0.037964146584272385
loss: 0.10642347484827042, Performance is better... saving the model
train loss = 0.037964947521686554
loss: 0.1063215360045433, Performance is better... saving the model
train loss = 0.03794822841882706
loss: 0.10655179619789124, EarlyStopping counter: 1 out of 10
train loss = 0.03791728988289833
loss: 0.10627254098653793, Performance is better... saving the model
train loss = 0.037886492908000946
loss: 0.10640699416399002, EarlyStopping counter: 1 out of 10
train loss = 0.037871308624744415
loss: 0.106377512216568, EarlyStopping counter: 2 out of 10
train loss = 0.03784835338592529
loss: 0.10632050037384033, EarlyStopping counter: 3 out of 10
train loss = 0.037825021892786026
loss: 0.10649953037500381, EarlyStopping counter: 4 out of 10
train loss = 0.03781963139772415
loss: 0.10630243271589279, EarlyStopping counter: 5 out of 10
train loss = 0.03778086230158806
loss: 0.10607706755399704, Performance is better... saving the model
train loss = 0.0377596952021122
loss: 0.10632271319627762, EarlyStopping counter: 1 out of 10
train loss = 0.03773139789700508
loss: 0.10648955404758453, EarlyStopping counter: 2 out of 10
train loss = 0.037708789110183716
loss: 0.10634994506835938, EarlyStopping counter: 3 out of 10
train loss = 0.037673719227313995
loss: 0.10631407052278519, EarlyStopping counter: 4 out of 10
train loss = 0.03765410929918289
loss: 0.10618536919355392, EarlyStopping counter: 5 out of 10
train loss = 0.03762543201446533
loss: 0.10624869167804718, EarlyStopping counter: 6 out of 10
train loss = 0.037601880729198456
loss: 0.10588464140892029, Performance is better... saving the model
train loss = 0.037589844316244125
loss: 0.10607180744409561, EarlyStopping counter: 1 out of 10
train loss = 0.03756655007600784
loss: 0.10617928206920624, EarlyStopping counter: 2 out of 10
train loss = 0.03754379600286484
loss: 0.10601756721735, EarlyStopping counter: 3 out of 10
train loss = 0.03751827031373978
loss: 0.1063634529709816, EarlyStopping counter: 4 out of 10
train loss = 0.03750959783792496
loss: 0.10607945173978806, EarlyStopping counter: 5 out of 10
train loss = 0.037448130548000336
loss: 0.10628556460142136, EarlyStopping counter: 6 out of 10
train loss = 0.03741075471043587
loss: 0.10596531629562378, EarlyStopping counter: 7 out of 10
train loss = 0.037396855652332306
loss: 0.10595261305570602, EarlyStopping counter: 8 out of 10
train loss = 0.03739144653081894
loss: 0.10576842725276947, Performance is better... saving the model
train loss = 0.03733355179429054
loss: 0.10585048049688339, EarlyStopping counter: 1 out of 10
train loss = 0.03731268644332886
loss: 0.10600019246339798, EarlyStopping counter: 2 out of 10
train loss = 0.0373062826693058
loss: 0.10576290637254715, Performance is better... saving the model
train loss = 0.03726918622851372
loss: 0.1059565395116806, EarlyStopping counter: 1 out of 10
train loss = 0.037229299545288086
loss: 0.10601009428501129, EarlyStopping counter: 2 out of 10
train loss = 0.03724437952041626
loss: 0.10584858804941177, EarlyStopping counter: 3 out of 10
train loss = 0.037198688834905624
loss: 0.10604048520326614, EarlyStopping counter: 4 out of 10
train loss = 0.0371890589594841
loss: 0.10569661110639572, Performance is better... saving the model
train loss = 0.03716327250003815









































100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [18:53<00:00, 27.64s/it]
For top100, metric recall = 0.04663350027045638
For top300, metric recall = 0.09410003848454715
For top100, metric hit_ratio = 0.30063049871116865
For top300, metric hit_ratio = 0.47756949402780974
For top100, metric coverage = 39.23600740624206
For top300, metric coverage = 89.6662108358646
loss: 0.1057819053530693, EarlyStopping counter: 1 out of 10
train loss = 0.03713914752006531
loss: 0.10579560697078705, EarlyStopping counter: 2 out of 10
train loss = 0.03709036856889725
loss: 0.10571128875017166, EarlyStopping counter: 3 out of 10
train loss = 0.03710123151540756
loss: 0.10567643493413925, Performance is better... saving the model
train loss = 0.037060774862766266
loss: 0.10568017512559891, EarlyStopping counter: 1 out of 10
train loss = 0.037092067301273346
loss: 0.10578317940235138, EarlyStopping counter: 2 out of 10
train loss = 0.037038467824459076
loss: 0.10558132082223892, Performance is better... saving the model
train loss = 0.03699430450797081
loss: 0.105840303003788, EarlyStopping counter: 1 out of 10
train loss = 0.037005264312028885
loss: 0.10565647482872009, EarlyStopping counter: 2 out of 10
train loss = 0.03696773201227188
loss: 0.10572308301925659, EarlyStopping counter: 3 out of 10
train loss = 0.036958884447813034
loss: 0.10564988851547241, EarlyStopping counter: 4 out of 10
train loss = 0.036924686282873154
loss: 0.10548830032348633, Performance is better... saving the model
train loss = 0.03689177334308624
loss: 0.10562880337238312, EarlyStopping counter: 1 out of 10
train loss = 0.03687801584601402
loss: 0.10576217621564865, EarlyStopping counter: 2 out of 10
train loss = 0.03687308728694916
loss: 0.10549193620681763, EarlyStopping counter: 3 out of 10
train loss = 0.036808546632528305
loss: 0.10570912808179855, EarlyStopping counter: 4 out of 10
train loss = 0.03680044412612915
loss: 0.10580535233020782, EarlyStopping counter: 5 out of 10
train loss = 0.03676474466919899
loss: 0.10586150735616684, EarlyStopping counter: 6 out of 10
train loss = 0.03678882494568825
loss: 0.1055956706404686, EarlyStopping counter: 7 out of 10
train loss = 0.03672904893755913
loss: 0.10542473196983337, Performance is better... saving the model
train loss = 0.03671209514141083
loss: 0.10573258250951767, EarlyStopping counter: 1 out of 10
train loss = 0.03670182824134827
loss: 0.10547023266553879, EarlyStopping counter: 2 out of 10
train loss = 0.03668980300426483
loss: 0.10561185330152512, EarlyStopping counter: 3 out of 10
train loss = 0.03664286434650421
loss: 0.10561024397611618, EarlyStopping counter: 4 out of 10
train loss = 0.03664124757051468
loss: 0.10551200807094574, EarlyStopping counter: 5 out of 10
train loss = 0.036613404750823975
loss: 0.10537480562925339, Performance is better... saving the model
train loss = 0.03659670054912567
loss: 0.10538094490766525, EarlyStopping counter: 1 out of 10
train loss = 0.03655438870191574
loss: 0.10528501123189926, Performance is better... saving the model
train loss = 0.036540865898132324
loss: 0.1055714413523674, EarlyStopping counter: 1 out of 10
train loss = 0.036554004997015
loss: 0.1053275540471077, EarlyStopping counter: 2 out of 10
train loss = 0.03650256618857384
loss: 0.10535798221826553, EarlyStopping counter: 3 out of 10
train loss = 0.036467790603637695
loss: 0.10540058463811874, EarlyStopping counter: 4 out of 10
train loss = 0.036478571593761444
loss: 0.10537471622228622, EarlyStopping counter: 5 out of 10
train loss = 0.03644001483917236
loss: 0.10535871982574463, EarlyStopping counter: 6 out of 10
train loss = 0.03641746938228607
loss: 0.10516267269849777, Performance is better... saving the model
train loss = 0.03638406842947006
loss: 0.10552309453487396, EarlyStopping counter: 1 out of 10
train loss = 0.036393385380506516
loss: 0.10528452694416046, EarlyStopping counter: 2 out of 10
train loss = 0.03638504445552826
loss: 0.1052812784910202, EarlyStopping counter: 3 out of 10
train loss = 0.036368101835250854
loss: 0.1052616760134697, EarlyStopping counter: 4 out of 10
train loss = 0.036365408450365067
loss: 0.10525871068239212, EarlyStopping counter: 5 out of 10
train loss = 0.036313895136117935
loss: 0.10528054088354111, EarlyStopping counter: 6 out of 10
train loss = 0.036293067038059235
loss: 0.10548249632120132, EarlyStopping counter: 7 out of 10
train loss = 0.03628882020711899
loss: 0.10533472150564194, EarlyStopping counter: 8 out of 10
train loss = 0.03625073656439781
loss: 0.10538388043642044, EarlyStopping counter: 9 out of 10
train loss = 0.036253564059734344
loss: 0.10556906461715698, EarlyStopping counter: 10 out of 10
loading best model for test
begin testing









































100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 41/41 [18:51<00:00, 27.59s/it]
For top100, metric recall = 0.04738230849272601
For top300, metric recall = 0.09500612772779313
For top100, metric hit_ratio = 0.30369222949669017
For top300, metric hit_ratio = 0.4810184793000375
For top100, metric coverage = 38.8788740575799
For top300, metric coverage = 88.84089891447726