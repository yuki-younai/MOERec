loadding data
reading category information





100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 136710/136710 [00:13<00:00, 10142.77it/s]
reading train data



100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2571752/2571752 [00:04<00:00, 516263.59it/s]
reading valid data
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 845781/845781 [00:01<00:00, 500701.93it/s]
reading test data
get weight for each sample
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 136710/136710 [00:00<00:00, 2539846.21it/s]
model already setting
train loss = 0.3392277657985687
loss: 0.37952178716659546, Performance is better... saving the model
train loss = 0.3034765124320984
loss: 0.35377445816993713, Performance is better... saving the model
train loss = 0.27119410037994385
Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
loss: 0.33304542303085327, Performance is better... saving the model
train loss = 0.24722635746002197
loss: 0.31948864459991455, Performance is better... saving the model
train loss = 0.23001855611801147
loss: 0.30618318915367126, Performance is better... saving the model
train loss = 0.2158978432416916
loss: 0.29561156034469604, Performance is better... saving the model
train loss = 0.20387272536754608
loss: 0.2868746519088745, Performance is better... saving the model
train loss = 0.1937810182571411
loss: 0.2762647271156311, Performance is better... saving the model
train loss = 0.18525050580501556
loss: 0.269888699054718, Performance is better... saving the model
train loss = 0.17742778360843658
loss: 0.26194822788238525, Performance is better... saving the model
train loss = 0.17086803913116455
loss: 0.2544839680194855, Performance is better... saving the model
train loss = 0.1651231348514557
loss: 0.24845604598522186, Performance is better... saving the model
train loss = 0.1596987545490265
loss: 0.24226243793964386, Performance is better... saving the model
train loss = 0.1549924612045288
loss: 0.23681606352329254, Performance is better... saving the model
train loss = 0.15085870027542114
loss: 0.23143763840198517, Performance is better... saving the model
train loss = 0.14699892699718475
loss: 0.22746701538562775, Performance is better... saving the model
train loss = 0.14358001947402954
loss: 0.2236374467611313, Performance is better... saving the model
train loss = 0.14034529030323029
loss: 0.21946817636489868, Performance is better... saving the model
train loss = 0.13744257390499115
loss: 0.2159457504749298, Performance is better... saving the model
train loss = 0.1347832828760147
loss: 0.21219360828399658, Performance is better... saving the model
train loss = 0.13231328129768372
loss: 0.20920297503471375, Performance is better... saving the model
train loss = 0.1299598664045334
loss: 0.20676547288894653, Performance is better... saving the model
train loss = 0.1278221607208252
loss: 0.20456326007843018, Performance is better... saving the model
train loss = 0.12576599419116974
loss: 0.20207084715366364, Performance is better... saving the model
train loss = 0.12390945106744766
loss: 0.2002062201499939, Performance is better... saving the model
train loss = 0.12207043170928955
