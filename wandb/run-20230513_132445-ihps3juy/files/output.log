loadding data
reading category information





100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 136710/136710 [00:13<00:00, 9942.28it/s]
reading train data



100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2571752/2571752 [00:05<00:00, 477651.71it/s]
reading valid data
100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 845781/845781 [00:01<00:00, 472796.51it/s]
reading test data
model already setting
get weight for each sample
100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 136710/136710 [00:00<00:00, 2553554.87it/s]
tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0610, device='cuda:0', grad_fn=<AddBackward0>)
Starting new HTTPS connection (1): o151352.ingest.sentry.io:443
tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)
https://o151352.ingest.sentry.io:443 "POST /api/5288891/envelope/ HTTP/1.1" 200 2
train loss = 0.19682945311069489
tensor(0.0859, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.20355600118637085, Performance is better... saving the model
tensor(0.0883, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0885, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0874, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0885, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.2018887996673584
loss: 0.20163673162460327, Performance is better... saving the model
tensor(0.0766, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0771, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0768, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0760, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0772, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.1994633674621582
tensor(0.0649, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.1992485374212265, Performance is better... saving the model
tensor(0.0646, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0648, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.19690553843975067
tensor(0.0689, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.2000126838684082, EarlyStopping counter: 1 out of 10
tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0668, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0707, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0695, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.19769972562789917
tensor(0.0677, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19974209368228912, EarlyStopping counter: 2 out of 10
tensor(0.0677, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0681, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0671, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.19733992218971252
tensor(0.0635, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19884607195854187, Performance is better... saving the model
tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0629, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0640, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.19636523723602295
tensor(0.0629, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19871403276920319, Performance is better... saving the model
tensor(0.0635, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0642, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.19626204669475555
tensor(0.0639, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.1988886594772339, EarlyStopping counter: 1 out of 10
tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0630, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.19608792662620544
tensor(0.0613, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19834332168102264, Performance is better... saving the model
tensor(0.0630, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.1958184689283371
tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.1985030323266983, EarlyStopping counter: 1 out of 10
tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0633, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.1958022564649582
tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19846010208129883, EarlyStopping counter: 2 out of 10
tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0629, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.19582974910736084
tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0607, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19810368120670319, Performance is better... saving the model
tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0633, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.19579416513442993
tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19827629625797272, EarlyStopping counter: 1 out of 10
tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0604, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.19542904198169708
tensor(0.0623, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19829249382019043, EarlyStopping counter: 2 out of 10
tensor(0.0619, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0603, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0596, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.1950901597738266
tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.1981959044933319, EarlyStopping counter: 3 out of 10
tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0614, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.1951705813407898
tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.1980970948934555, Performance is better... saving the model
tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0630, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0615, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.1949271857738495
tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19762738049030304, Performance is better... saving the model
tensor(0.0614, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0602, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.1944965124130249
tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19733789563179016, Performance is better... saving the model
tensor(0.0633, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0615, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0615, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.19418960809707642
tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.1972215473651886, Performance is better... saving the model
tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0614, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0619, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.1935674399137497
tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19673000276088715, Performance is better... saving the model
tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0608, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.19273343682289124
tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.1961214691400528, Performance is better... saving the model
tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0600, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0608, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0607, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.19174499809741974
tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0594, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19526077806949615, Performance is better... saving the model
tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.19087263941764832
tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19493813812732697, Performance is better... saving the model
tensor(0.0599, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0615, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.18974408507347107
tensor(0.0597, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19376005232334137, Performance is better... saving the model
tensor(0.0607, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0607, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0614, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0619, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.18870721757411957
tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19327101111412048, Performance is better... saving the model
tensor(0.0612, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0619, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0600, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.1876317262649536
tensor(0.0612, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19284096360206604, Performance is better... saving the model
tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0607, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0614, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0607, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.18665769696235657
tensor(0.0611, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19234539568424225, Performance is better... saving the model
tensor(0.0612, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0607, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0610, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.18570953607559204
tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19205351173877716, Performance is better... saving the model
tensor(0.0639, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0644, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0645, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.18545345962047577
tensor(0.0635, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0687, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19314692914485931, EarlyStopping counter: 1 out of 10
tensor(0.0677, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0676, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0694, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.1856720745563507
tensor(0.0685, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0791, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19505244493484497, EarlyStopping counter: 2 out of 10
tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0800, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0787, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0795, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.18728163838386536
tensor(0.0712, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19353021681308746, EarlyStopping counter: 3 out of 10
tensor(0.0715, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0723, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0729, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0720, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.18527185916900635
tensor(0.0703, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19282649457454681, EarlyStopping counter: 4 out of 10
tensor(0.0707, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0716, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0706, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0703, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.18459509313106537
tensor(0.0642, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19181185960769653, Performance is better... saving the model
tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0647, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0641, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.1827138364315033
tensor(0.0695, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19245880842208862, EarlyStopping counter: 1 out of 10
tensor(0.0688, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0687, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0690, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0706, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.18347375094890594
tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19104579091072083, Performance is better... saving the model
tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0644, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0644, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0650, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.1821012943983078
tensor(0.0608, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19007396697998047, Performance is better... saving the model
tensor(0.0612, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0609, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0623, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0616, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.18118131160736084
loss: 0.1906507909297943, EarlyStopping counter: 1 out of 10
tensor(0.0644, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0636, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0648, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0643, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.1813500076532364
tensor(0.0646, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.19041171669960022, EarlyStopping counter: 2 out of 10
tensor(0.0660, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0635, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0651, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.18103404343128204
tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.18958084285259247, Performance is better... saving the model
tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0639, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0635, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.18023602664470673
tensor(0.0627, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.1892002373933792, Performance is better... saving the model
tensor(0.0612, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0617, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0623, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0599, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.17931367456912994
tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.18893738090991974, Performance is better... saving the model
tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0629, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.1790182739496231
tensor(0.0644, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.18878057599067688, Performance is better... saving the model
tensor(0.0640, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0642, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0658, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0639, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.17877919971942902
tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.18789337575435638, Performance is better... saving the model
tensor(0.0603, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0615, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0604, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.17737066745758057
tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.18738433718681335, Performance is better... saving the model
tensor(0.0618, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0624, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0605, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.17678102850914001
tensor(0.0627, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.18692386150360107, Performance is better... saving the model
tensor(0.0629, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0640, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0627, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0641, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.17634129524230957
tensor(0.0631, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.18650312721729279, Performance is better... saving the model
tensor(0.0632, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0639, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0639, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0620, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.17540112137794495
tensor(0.0622, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.18557462096214294, Performance is better... saving the model
tensor(0.0621, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0606, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0613, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0608, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.1740780621767044
tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.18519559502601624, Performance is better... saving the model
tensor(0.0637, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0630, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0625, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0626, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.17344969511032104
tensor(0.0635, device='cuda:0', grad_fn=<AddBackward0>)
loss: 0.18448567390441895, Performance is better... saving the model
tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0630, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0638, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0639, device='cuda:0', grad_fn=<AddBackward0>)
train loss = 0.172604501247406
tensor(0.0627, device='cuda:0', grad_fn=<AddBackward0>)
tensor(0.0634, device='cuda:0', grad_fn=<AddBackward0>)
  0%|                                                                                                                                                                                                                     | 0/41 [00:00<?, ?it/s]
Traceback (most recent call last):
  File "main.py", line 92, in <module>
    res,ndcg5_std,ndcg10_std,mrr_std,auc_std=tester.test()
  File "/home/gwy/BaseSAT/BaseGAT/utils/tester.py", line 89, in test
    scores = self.model.get_score(h, users)
  File "/home/gwy/BaseSAT/BaseGAT/models/models.py", line 82, in get_score
    user_embed = h['user'][users]
TypeError: tuple indices must be integers or slices, not str