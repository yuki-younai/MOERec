{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "from utils.parser import parse_args\n",
    "from utils.dataloader import Dataloader\n",
    "from utils.utils import config, construct_negative_graph, choose_model, load_mf_model, NegativeGraph\n",
    "from utils.tester import Tester\n",
    "from models.sampler import NegativeSampler\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', default = 'TaoBao', type = str,\n",
    "                    help = 'Dataset to use')\n",
    "parser.add_argument('--seed', default = 2022, type = int,\n",
    "                    help = 'seed for experiment')\n",
    "parser.add_argument('--embed_size', default = 32, type = int,\n",
    "                    help = 'embedding size for all layer')\n",
    "parser.add_argument('--lr', default = 0.05, type = float,\n",
    "                    help = 'learning rate')\n",
    "parser.add_argument('--weight_decay', default = 8e-8, type = float,\n",
    "                    help = \"weight decay for adam optimizer\")\n",
    "#######################################################################\n",
    "parser.add_argument('--model', default ='test',type = str,\n",
    "                    help = 'model selection')#dgrec base moe test\n",
    "parser.add_argument('--epoch', default = 1000, type = int,\n",
    "                    help = 'epoch number')\n",
    "parser.add_argument('--patience', default = 10, type = int,\n",
    "                    help = 'early_stop validation')\n",
    "parser.add_argument('--batch_size', default = 2048, type = int,\n",
    "                    help = 'batch size')\n",
    "parser.add_argument('--layers', default = 1, type = int,\n",
    "                    help = 'layer number')\n",
    "parser.add_argument('--gpu', default = 0, type = int,\n",
    "                    help = '-1 for cpu, 0 for gpu:0')\n",
    "parser.add_argument('--k_list', default = [100, 300], type = list,\n",
    "                    help = 'topk evaluation')\n",
    "parser.add_argument('--k', default = 20, type = int,\n",
    "                    help = 'neighbor number in each GNN aggregation')\n",
    "parser.add_argument('--neg_number', default = 4, type = int,\n",
    "                    help = 'negative sampler number for each positive pair')\n",
    "parser.add_argument('--metrics', default = ['recall', 'hit_ratio', 'coverage'])\n",
    "\n",
    "\n",
    "parser.add_argument('--sigma', default = 1.0, type = float,\n",
    "                    help = 'sigma for gaussian kernel')\n",
    "parser.add_argument('--gamma', default = 2.0, type = float,\n",
    "                    help = 'gamma for gaussian kernel')\n",
    "################################################################################\n",
    "parser.add_argument('--category_balance', default = True, type = bool,\n",
    "                    help = 'whether make loss category balance')\n",
    "parser.add_argument('--beta_class', default = 0.9, type = float,\n",
    "                    help = 'class re-balanced loss beta')\n",
    "parser.add_argument('--context_code_dim', default = 32, type = int,\n",
    "                    help = 'interest num')\n",
    "parser.add_argument('--num_context_codes', default = 32, type = int,\n",
    "                    help = 'interest dim')\n",
    "parser.add_argument('--n_experts', default = 5, type = int,\n",
    "                    help = 'n_experts')\n",
    "##########################################################################################\n",
    "parser.add_argument('--wandb_enable', default = True, type = bool,\n",
    "                    help = 'layer number')\n",
    "parser.add_argument('--hidden_size', default = 32, type = int,\n",
    "                        help = 'n_experts')\n",
    "parser.add_argument('--k_experts', default = 2, type = int,\n",
    "                            help = 'n_experts')\n",
    "parser.add_argument('--moe', default = False, type = bool,\n",
    "                            help = 'layer number')\n",
    "################################################################################\n",
    "parser.add_argument('--sub', default = 'rand', type = str,\n",
    "                            help = 'layer number')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136710/136710 [00:07<00:00, 19456.90it/s]\n",
      "100%|██████████| 2571752/2571752 [00:03<00:00, 768836.54it/s]\n",
      "100%|██████████| 845781/845781 [00:00<00:00, 878513.19it/s] \n",
      "100%|██████████| 136710/136710 [00:00<00:00, 4557076.78it/s]\n"
     ]
    }
   ],
   "source": [
    "data = args.dataset\n",
    "if args.gpu >= 0 and torch.cuda.is_available():\n",
    "        device = 'cuda:{}'.format(args.gpu)\n",
    "else:\n",
    "        device = 'cpu'\n",
    "device = torch.device(device)\n",
    "args.device = device\n",
    "dataloader = Dataloader(args, data, device)\n",
    "graph = dataloader.train_graph\n",
    "\n",
    "hid_dim = args.embed_size\n",
    "user_embedding = torch.nn.Parameter(torch.randn(graph.nodes('user').shape[0], hid_dim))\n",
    "item_embedding = torch.nn.Parameter(torch.randn(graph.nodes('item').shape[0], hid_dim))\n",
    "node_features = {'user': user_embedding, 'item': item_embedding}\n",
    "etype=('item', 'rated by', 'user')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dataloader.train_graph\n",
    "feat_src = node_features['item'].to(device)\n",
    "graph.nodes['item'].data['h'] = feat_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(X, sigma = 1.0, gamma = 2.0):\n",
    "        dists = torch.cdist(X, X)\n",
    "        sims = torch.exp(-dists / (sigma * dists.mean(dim = -1).mean(dim = -1).reshape(-1, 1, 1)))\n",
    "        return sims\n",
    "import math\n",
    "import random\n",
    "maxlen=20\n",
    "def submodular_selection_feature(nodes):\n",
    "        device = nodes.mailbox['m'].device\n",
    "        mail = nodes.mailbox['m']\n",
    "        batch_size, neighbor_size, feature_size = mail.shape\n",
    "        cat=nodes.mailbox['c']\n",
    "        user_select=[]\n",
    "        for i in range(batch_size):\n",
    "            select=[]\n",
    "            line=cat[i].reshape(1,-1)[0].tolist()\n",
    "            unique_elements = list(set(line))\n",
    "            element_counts = [line.count(element) for element in unique_elements]\n",
    "            element_indices = {}\n",
    "            for index, element in enumerate(line):\n",
    "                if element in element_indices:\n",
    "                   element_indices[element].append(index)\n",
    "                else:\n",
    "                   element_indices[element] = [index]\n",
    "            avg=math.ceil(sum(element_counts)/len(element_counts))\n",
    "\n",
    "            sorted_indices = sorted(range(len(element_counts)), key=lambda i: element_counts[i], reverse=True)\n",
    "\n",
    "            for i in sorted_indices:\n",
    "               my_list=element_indices[unique_elements[i]]\n",
    "               if int(len(my_list)/2)>avg:\n",
    "                   random_elements = random.sample(my_list,int(len(my_list)/2))\n",
    "               else:\n",
    "                   random_elements=random.sample(my_list, k=min(avg,len(my_list)))\n",
    "               select=select+random_elements\n",
    "            if len(select)>=maxlen:\n",
    "                select=select[0:maxlen]\n",
    "            else:\n",
    "                select=select+select[0:maxlen-len(select)]\n",
    "            user_select.append(select)\n",
    "            \n",
    "        user_select=torch.tensor(user_select)\n",
    "\n",
    "        return user_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dic=[]\n",
    "import math\n",
    "num=[]\n",
    "ma=[]\n",
    "def category_aggregation(edges):\n",
    "        return {'c': edges.src['category'], 'm': edges.src['h']}\n",
    "def sub_reduction_item_user(nodes):\n",
    "        # -1 indicate user-> node, which does not include category information\n",
    "        mail = nodes.mailbox['m']\n",
    "        batch_size, neighbor_size, feature_size = mail.shape\n",
    "                  \n",
    "    \n",
    "        if (-1 in nodes.mailbox['c']) or nodes.mailbox['m'].shape[1] <=20:\n",
    "            \n",
    "            mail=mail.sum(dim=1)\n",
    "        else:\n",
    "            neighbors = submodular_selection_feature(nodes)     \n",
    "            print(neighbors.shape)\n",
    "            mail = mail[torch.arange(batch_size, dtype = torch.long, device = mail.device).unsqueeze(-1), neighbors]\n",
    "            mail=mail.sum(dim=1)\n",
    "        #mail=mail.sum(dim=1)\n",
    "        return {'h': mail}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2237, 20])\n",
      "torch.Size([1087, 20])\n",
      "torch.Size([2212, 20])\n",
      "torch.Size([1934, 20])\n",
      "torch.Size([907, 20])\n",
      "torch.Size([1748, 20])\n",
      "torch.Size([1721, 20])\n",
      "torch.Size([833, 20])\n",
      "torch.Size([1549, 20])\n",
      "torch.Size([1548, 20])\n",
      "torch.Size([680, 20])\n",
      "torch.Size([1332, 20])\n",
      "torch.Size([1346, 20])\n",
      "torch.Size([629, 20])\n",
      "torch.Size([1262, 20])\n",
      "torch.Size([1190, 20])\n",
      "torch.Size([577, 20])\n",
      "torch.Size([1093, 20])\n",
      "torch.Size([1084, 20])\n",
      "torch.Size([490, 20])\n",
      "torch.Size([984, 20])\n",
      "torch.Size([919, 20])\n",
      "torch.Size([453, 20])\n",
      "torch.Size([824, 20])\n",
      "torch.Size([832, 20])\n",
      "torch.Size([402, 20])\n",
      "torch.Size([744, 20])\n",
      "torch.Size([691, 20])\n",
      "torch.Size([324, 20])\n",
      "torch.Size([673, 20])\n",
      "torch.Size([641, 20])\n",
      "torch.Size([273, 20])\n",
      "torch.Size([587, 20])\n",
      "torch.Size([641, 20])\n",
      "torch.Size([255, 20])\n",
      "torch.Size([548, 20])\n",
      "torch.Size([498, 20])\n",
      "torch.Size([251, 20])\n",
      "torch.Size([527, 20])\n",
      "torch.Size([460, 20])\n",
      "torch.Size([224, 20])\n",
      "torch.Size([408, 20])\n",
      "torch.Size([398, 20])\n",
      "torch.Size([203, 20])\n",
      "torch.Size([345, 20])\n",
      "torch.Size([358, 20])\n",
      "torch.Size([177, 20])\n",
      "torch.Size([354, 20])\n",
      "torch.Size([316, 20])\n",
      "torch.Size([156, 20])\n",
      "torch.Size([290, 20])\n",
      "torch.Size([292, 20])\n",
      "torch.Size([132, 20])\n",
      "torch.Size([257, 20])\n",
      "torch.Size([271, 20])\n",
      "torch.Size([116, 20])\n",
      "torch.Size([255, 20])\n",
      "torch.Size([242, 20])\n",
      "torch.Size([111, 20])\n",
      "torch.Size([201, 20])\n",
      "torch.Size([208, 20])\n",
      "torch.Size([95, 20])\n",
      "torch.Size([175, 20])\n",
      "torch.Size([163, 20])\n",
      "torch.Size([81, 20])\n",
      "torch.Size([191, 20])\n",
      "torch.Size([165, 20])\n",
      "torch.Size([90, 20])\n",
      "torch.Size([145, 20])\n",
      "torch.Size([155, 20])\n",
      "torch.Size([73, 20])\n",
      "torch.Size([131, 20])\n",
      "torch.Size([134, 20])\n",
      "torch.Size([78, 20])\n",
      "torch.Size([124, 20])\n",
      "torch.Size([82, 20])\n",
      "torch.Size([45, 20])\n",
      "torch.Size([122, 20])\n",
      "torch.Size([99, 20])\n",
      "torch.Size([50, 20])\n",
      "torch.Size([101, 20])\n",
      "torch.Size([91, 20])\n",
      "torch.Size([40, 20])\n",
      "torch.Size([72, 20])\n",
      "torch.Size([80, 20])\n",
      "torch.Size([38, 20])\n",
      "torch.Size([81, 20])\n",
      "torch.Size([48, 20])\n",
      "torch.Size([31, 20])\n",
      "torch.Size([69, 20])\n",
      "torch.Size([66, 20])\n",
      "torch.Size([33, 20])\n",
      "torch.Size([52, 20])\n",
      "torch.Size([64, 20])\n",
      "torch.Size([25, 20])\n",
      "torch.Size([51, 20])\n",
      "torch.Size([45, 20])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([40, 20])\n",
      "torch.Size([29, 20])\n",
      "torch.Size([23, 20])\n",
      "torch.Size([34, 20])\n",
      "torch.Size([40, 20])\n",
      "torch.Size([16, 20])\n",
      "torch.Size([37, 20])\n",
      "torch.Size([27, 20])\n",
      "torch.Size([12, 20])\n",
      "torch.Size([21, 20])\n",
      "torch.Size([28, 20])\n",
      "torch.Size([18, 20])\n",
      "torch.Size([30, 20])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([12, 20])\n",
      "torch.Size([21, 20])\n",
      "torch.Size([29, 20])\n",
      "torch.Size([13, 20])\n",
      "torch.Size([15, 20])\n",
      "torch.Size([20, 20])\n",
      "torch.Size([10, 20])\n",
      "torch.Size([26, 20])\n",
      "torch.Size([17, 20])\n",
      "torch.Size([9, 20])\n",
      "torch.Size([8, 20])\n",
      "torch.Size([23, 20])\n",
      "torch.Size([6, 20])\n",
      "torch.Size([13, 20])\n",
      "torch.Size([17, 20])\n",
      "torch.Size([7, 20])\n",
      "torch.Size([12, 20])\n",
      "torch.Size([7, 20])\n",
      "torch.Size([7, 20])\n",
      "torch.Size([10, 20])\n",
      "torch.Size([11, 20])\n",
      "torch.Size([4, 20])\n",
      "torch.Size([6, 20])\n",
      "torch.Size([9, 20])\n",
      "torch.Size([5, 20])\n",
      "torch.Size([10, 20])\n",
      "torch.Size([13, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([5, 20])\n",
      "torch.Size([6, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([3, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([3, 20])\n",
      "torch.Size([3, 20])\n",
      "torch.Size([5, 20])\n",
      "torch.Size([5, 20])\n",
      "torch.Size([5, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([4, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([3, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([5, 20])\n",
      "torch.Size([3, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([4, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([3, 20])\n",
      "torch.Size([7, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([2, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 20])\n"
     ]
    }
   ],
   "source": [
    "with graph.local_scope():\n",
    "    graph.update_all(category_aggregation, sub_reduction_item_user, etype = etype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
