{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "from utils.parser import parse_args\n",
    "from utils.dataloader import Dataloader\n",
    "from utils.utils import config, construct_negative_graph, choose_model, load_mf_model, NegativeGraph\n",
    "from utils.tester import Tester\n",
    "from models.sampler import NegativeSampler\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', default = 'TaoBao', type = str,\n",
    "                    help = 'Dataset to use')\n",
    "parser.add_argument('--seed', default = 2022, type = int,\n",
    "                    help = 'seed for experiment')\n",
    "parser.add_argument('--embed_size', default = 32, type = int,\n",
    "                    help = 'embedding size for all layer')\n",
    "parser.add_argument('--lr', default = 0.05, type = float,\n",
    "                    help = 'learning rate')\n",
    "parser.add_argument('--weight_decay', default = 8e-8, type = float,\n",
    "                    help = \"weight decay for adam optimizer\")\n",
    "#######################################################################\n",
    "parser.add_argument('--model', default ='test',type = str,\n",
    "                    help = 'model selection')#dgrec base moe test\n",
    "parser.add_argument('--epoch', default = 1000, type = int,\n",
    "                    help = 'epoch number')\n",
    "parser.add_argument('--patience', default = 10, type = int,\n",
    "                    help = 'early_stop validation')\n",
    "parser.add_argument('--batch_size', default = 2048, type = int,\n",
    "                    help = 'batch size')\n",
    "parser.add_argument('--layers', default = 1, type = int,\n",
    "                    help = 'layer number')\n",
    "parser.add_argument('--gpu', default = 0, type = int,\n",
    "                    help = '-1 for cpu, 0 for gpu:0')\n",
    "parser.add_argument('--k_list', default = [100, 300], type = list,\n",
    "                    help = 'topk evaluation')\n",
    "parser.add_argument('--k', default = 20, type = int,\n",
    "                    help = 'neighbor number in each GNN aggregation')\n",
    "parser.add_argument('--neg_number', default = 4, type = int,\n",
    "                    help = 'negative sampler number for each positive pair')\n",
    "parser.add_argument('--metrics', default = ['recall', 'hit_ratio', 'coverage'])\n",
    "\n",
    "\n",
    "parser.add_argument('--sigma', default = 1.0, type = float,\n",
    "                    help = 'sigma for gaussian kernel')\n",
    "parser.add_argument('--gamma', default = 2.0, type = float,\n",
    "                    help = 'gamma for gaussian kernel')\n",
    "################################################################################\n",
    "parser.add_argument('--category_balance', default = True, type = bool,\n",
    "                    help = 'whether make loss category balance')\n",
    "parser.add_argument('--beta_class', default = 0.9, type = float,\n",
    "                    help = 'class re-balanced loss beta')\n",
    "parser.add_argument('--context_code_dim', default = 32, type = int,\n",
    "                    help = 'interest num')\n",
    "parser.add_argument('--num_context_codes', default = 32, type = int,\n",
    "                    help = 'interest dim')\n",
    "parser.add_argument('--n_experts', default = 5, type = int,\n",
    "                    help = 'n_experts')\n",
    "##########################################################################################\n",
    "parser.add_argument('--wandb_enable', default = True, type = bool,\n",
    "                    help = 'layer number')\n",
    "parser.add_argument('--hidden_size', default = 32, type = int,\n",
    "                        help = 'n_experts')\n",
    "parser.add_argument('--k_experts', default = 2, type = int,\n",
    "                            help = 'n_experts')\n",
    "parser.add_argument('--moe', default = False, type = bool,\n",
    "                            help = 'layer number')\n",
    "################################################################################\n",
    "parser.add_argument('--sub', default = 'rand', type = str,\n",
    "                            help = 'layer number')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136710/136710 [00:07<00:00, 18371.36it/s]\n",
      "100%|██████████| 2571752/2571752 [00:03<00:00, 756702.36it/s] \n",
      "100%|██████████| 845781/845781 [00:01<00:00, 790251.49it/s] \n",
      "100%|██████████| 136710/136710 [00:00<00:00, 3562661.85it/s]\n"
     ]
    }
   ],
   "source": [
    "data = args.dataset\n",
    "if args.gpu >= 0 and torch.cuda.is_available():\n",
    "        device = 'cuda:{}'.format(args.gpu)\n",
    "else:\n",
    "        device = 'cpu'\n",
    "device = torch.device(device)\n",
    "args.device = device\n",
    "dataloader = Dataloader(args, data, device)\n",
    "graph = dataloader.train_graph\n",
    "\n",
    "hid_dim = args.embed_size\n",
    "user_embedding = torch.nn.Parameter(torch.randn(graph.nodes('user').shape[0], hid_dim))\n",
    "item_embedding = torch.nn.Parameter(torch.randn(graph.nodes('item').shape[0], hid_dim))\n",
    "node_features = {'user': user_embedding, 'item': item_embedding}\n",
    "etype=('item', 'rated by', 'user')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dataloader.train_graph\n",
    "feat_src = node_features['item'].to(device)\n",
    "graph.nodes['item'].data['h'] = feat_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "maxlen=20\n",
    "def cate_topsis(numbers):\n",
    "        square_sum=math.sqrt(sum(i**2 for i in numbers))\n",
    "        numbers = [math.exp(x/square_sum) for x in numbers]\n",
    "        ma=max(numbers)\n",
    "        mi=0.5*min(numbers)\n",
    "        result=[(x-mi) /(ma-mi) for x in numbers]\n",
    "        result = [x / sum(result) for x in result]\n",
    "        result=[math.ceil(x*maxlen) for x in result]\n",
    "        return result\n",
    "def submodular_selection_feature(nodes):\n",
    "        device = nodes.mailbox['m'].device\n",
    "        mail = nodes.mailbox['m']\n",
    "        batch_size, neighbor_size, feature_size = mail.shape\n",
    "        cat=nodes.mailbox['c']\n",
    "        user_select=[]\n",
    "        for i in range(batch_size):\n",
    "            select=[]\n",
    "            line=cat[i].reshape(1,-1)[0].tolist()\n",
    "            unique_elements = list(set(line))\n",
    "            element_counts = [line.count(element) for element in unique_elements]\n",
    "            \n",
    "            element_indices = {}\n",
    "            for index, element in enumerate(line):\n",
    "                if element in element_indices:\n",
    "                   element_indices[element].append(index)\n",
    "                else:\n",
    "                   element_indices[element] = [index]\n",
    "        \n",
    "            sorted_indices = sorted(range(len(element_counts)), key=lambda i: element_counts[i], reverse=True)\n",
    "            cat_number=cate_topsis(element_counts)\n",
    "            for i in sorted_indices:\n",
    "               my_list=element_indices[unique_elements[i]]\n",
    "               random_elements=random.choices(my_list, k=cat_number[i])\n",
    "               select=select+random_elements\n",
    "               if len(select)>=maxlen:\n",
    "                   break\n",
    "            if len(select)>=maxlen:\n",
    "                select=select[0:maxlen]\n",
    "            else:\n",
    "                select=select+select[0:maxlen-len(select)]\n",
    "            if(len(select)<20):\n",
    "                print(\"start\")    \n",
    "                print(line)\n",
    "                print(unique_elements)\n",
    "                print(element_counts)\n",
    "                print(sorted_indices)\n",
    "                print(cat_number)\n",
    "                print(select)\n",
    "                print(\"end\")\n",
    "            user_select.append(select)\n",
    "        #print(user_select.shape)\n",
    "        user_select=torch.tensor(user_select)\n",
    "        \n",
    "\n",
    "        return user_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "def category_aggregation(edges):\n",
    "        return {'c': edges.src['category'], 'm': edges.src['h']}\n",
    "def sub_reduction_item_user(nodes):\n",
    "        # -1 indicate user-> node, which does not include category information\n",
    "        mail = nodes.mailbox['m']\n",
    "        batch_size, neighbor_size, feature_size = mail.shape\n",
    "                  \n",
    "    \n",
    "        if (-1 in nodes.mailbox['c']) or nodes.mailbox['m'].shape[1] <=20:\n",
    "            \n",
    "            mail=mail.sum(dim=1)\n",
    "        else:\n",
    "            cat=nodes.mailbox['c']\n",
    "            \n",
    "            neighbors=submodular_selection_feature(nodes)\n",
    "            mail = mail[torch.arange(batch_size, dtype = torch.long, device = mail.device).unsqueeze(-1), neighbors]\n",
    "            mail=mail.sum(dim=1)\n",
    "        \n",
    "        return {'h': mail}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.local_scope():\n",
    "    graph.update_all(category_aggregation, sub_reduction_item_user, etype = etype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 5, 5, 3, 3]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices([1,3,4,5,3,1], k=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
