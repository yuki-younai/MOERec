{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "from utils.parser import parse_args\n",
    "from utils.dataloader import Dataloader\n",
    "from utils.utils import config, construct_negative_graph, choose_model, load_mf_model, NegativeGraph\n",
    "from utils.tester import Tester\n",
    "from models.sampler import NegativeSampler\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', default = 'TaoBao', type = str,\n",
    "                    help = 'Dataset to use')\n",
    "parser.add_argument('--seed', default = 2022, type = int,\n",
    "                    help = 'seed for experiment')\n",
    "parser.add_argument('--embed_size', default = 32, type = int,\n",
    "                    help = 'embedding size for all layer')\n",
    "parser.add_argument('--lr', default = 0.05, type = float,\n",
    "                    help = 'learning rate')\n",
    "parser.add_argument('--weight_decay', default = 8e-8, type = float,\n",
    "                    help = \"weight decay for adam optimizer\")\n",
    "#######################################################################\n",
    "parser.add_argument('--model', default ='test',type = str,\n",
    "                    help = 'model selection')#dgrec base moe test\n",
    "parser.add_argument('--epoch', default = 1000, type = int,\n",
    "                    help = 'epoch number')\n",
    "parser.add_argument('--patience', default = 10, type = int,\n",
    "                    help = 'early_stop validation')\n",
    "parser.add_argument('--batch_size', default = 2048, type = int,\n",
    "                    help = 'batch size')\n",
    "parser.add_argument('--layers', default = 1, type = int,\n",
    "                    help = 'layer number')\n",
    "parser.add_argument('--gpu', default = 0, type = int,\n",
    "                    help = '-1 for cpu, 0 for gpu:0')\n",
    "parser.add_argument('--k_list', default = [100, 300], type = list,\n",
    "                    help = 'topk evaluation')\n",
    "parser.add_argument('--k', default = 20, type = int,\n",
    "                    help = 'neighbor number in each GNN aggregation')\n",
    "parser.add_argument('--neg_number', default = 4, type = int,\n",
    "                    help = 'negative sampler number for each positive pair')\n",
    "parser.add_argument('--metrics', default = ['recall', 'hit_ratio', 'coverage'])\n",
    "\n",
    "\n",
    "parser.add_argument('--sigma', default = 1.0, type = float,\n",
    "                    help = 'sigma for gaussian kernel')\n",
    "parser.add_argument('--gamma', default = 2.0, type = float,\n",
    "                    help = 'gamma for gaussian kernel')\n",
    "################################################################################\n",
    "parser.add_argument('--category_balance', default = True, type = bool,\n",
    "                    help = 'whether make loss category balance')\n",
    "parser.add_argument('--beta_class', default = 0.9, type = float,\n",
    "                    help = 'class re-balanced loss beta')\n",
    "parser.add_argument('--context_code_dim', default = 32, type = int,\n",
    "                    help = 'interest num')\n",
    "parser.add_argument('--num_context_codes', default = 32, type = int,\n",
    "                    help = 'interest dim')\n",
    "parser.add_argument('--n_experts', default = 5, type = int,\n",
    "                    help = 'n_experts')\n",
    "##########################################################################################\n",
    "parser.add_argument('--wandb_enable', default = True, type = bool,\n",
    "                    help = 'layer number')\n",
    "parser.add_argument('--hidden_size', default = 32, type = int,\n",
    "                        help = 'n_experts')\n",
    "parser.add_argument('--k_experts', default = 2, type = int,\n",
    "                            help = 'n_experts')\n",
    "parser.add_argument('--moe', default = False, type = bool,\n",
    "                            help = 'layer number')\n",
    "################################################################################\n",
    "parser.add_argument('--sub', default = 'rand', type = str,\n",
    "                            help = 'layer number')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136710/136710 [00:07<00:00, 18371.36it/s]\n",
      "100%|██████████| 2571752/2571752 [00:03<00:00, 756702.36it/s] \n",
      "100%|██████████| 845781/845781 [00:01<00:00, 790251.49it/s] \n",
      "100%|██████████| 136710/136710 [00:00<00:00, 3562661.85it/s]\n"
     ]
    }
   ],
   "source": [
    "data = args.dataset\n",
    "if args.gpu >= 0 and torch.cuda.is_available():\n",
    "        device = 'cuda:{}'.format(args.gpu)\n",
    "else:\n",
    "        device = 'cpu'\n",
    "device = torch.device(device)\n",
    "args.device = device\n",
    "dataloader = Dataloader(args, data, device)\n",
    "graph = dataloader.train_graph\n",
    "\n",
    "hid_dim = args.embed_size\n",
    "user_embedding = torch.nn.Parameter(torch.randn(graph.nodes('user').shape[0], hid_dim))\n",
    "item_embedding = torch.nn.Parameter(torch.randn(graph.nodes('item').shape[0], hid_dim))\n",
    "node_features = {'user': user_embedding, 'item': item_embedding}\n",
    "etype=('item', 'rated by', 'user')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dataloader.train_graph\n",
    "feat_src = node_features['item'].to(device)\n",
    "graph.nodes['item'].data['h'] = feat_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "maxlen=20\n",
    "def cate_topsis(numbers):\n",
    "        square_sum=math.sqrt(sum(i**2 for i in numbers))\n",
    "        numbers = [math.exp(x/square_sum) for x in numbers]\n",
    "        ma=max(numbers)\n",
    "        mi=0.5*min(numbers)\n",
    "        result=[(x-mi) /(ma-mi) for x in numbers]\n",
    "        result = [x / sum(result) for x in result]\n",
    "        result=[int(x*maxlen) for x in result]\n",
    "        return result\n",
    "def submodular_selection_feature(nodes):\n",
    "        device = nodes.mailbox['m'].device\n",
    "        mail = nodes.mailbox['m']\n",
    "        batch_size, neighbor_size, feature_size = mail.shape\n",
    "        cat=nodes.mailbox['c']\n",
    "        user_select=[]\n",
    "        for i in range(batch_size):\n",
    "            select=[]\n",
    "            line=cat[i].reshape(1,-1)[0].tolist()\n",
    "            unique_elements = list(set(line))\n",
    "            element_counts = [line.count(element) for element in unique_elements]\n",
    "            \n",
    "            element_indices = {}\n",
    "            for index, element in enumerate(line):\n",
    "                if element in element_indices:\n",
    "                   element_indices[element].append(index)\n",
    "                else:\n",
    "                   element_indices[element] = [index]\n",
    "        \n",
    "            sorted_indices = sorted(range(len(element_counts)), key=lambda i: element_counts[i], reverse=True)\n",
    "            cat_number=cate_topsis(element_counts)\n",
    "            print(line)\n",
    "            print(unique_elements)\n",
    "            print(element_counts)\n",
    "            print(sorted_indices)\n",
    "            print(cat_number)\n",
    "            for i in sorted_indices:\n",
    "               my_list=element_indices[unique_elements[i]]\n",
    "               random_elements=random.sample(my_list, k=cat_number[i])\n",
    "               select=select+random_elements\n",
    "               if len(select)>=maxlen:\n",
    "                   break\n",
    "            if len(select)>=maxlen:\n",
    "                select=select[0:maxlen]\n",
    "            else:\n",
    "                select=select+select[0:maxlen-len(select)]\n",
    "            user_select.append(select)\n",
    "            \n",
    "        user_select=torch.tensor(user_select)\n",
    "\n",
    "        return user_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "def category_aggregation(edges):\n",
    "        return {'c': edges.src['category'], 'm': edges.src['h']}\n",
    "def sub_reduction_item_user(nodes):\n",
    "        # -1 indicate user-> node, which does not include category information\n",
    "        mail = nodes.mailbox['m']\n",
    "        batch_size, neighbor_size, feature_size = mail.shape\n",
    "                  \n",
    "    \n",
    "        if (-1 in nodes.mailbox['c']) or nodes.mailbox['m'].shape[1] <=20:\n",
    "            \n",
    "            mail=mail.sum(dim=1)\n",
    "        else:\n",
    "            cat=nodes.mailbox['c']\n",
    "            \n",
    "            neighbors=submodular_selection_feature(nodes)\n",
    "            mail = mail[torch.arange(batch_size, dtype = torch.long, device = mail.device).unsqueeze(-1), neighbors]\n",
    "            mail=mail.sum(dim=1)\n",
    "        \n",
    "        return {'h': mail}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 225, 128, 120, 120, 227, 229, 216, 120, 120, 174, 174, 130, 120, 3, 2, 231, 232, 234, 128]\n",
      "[1, 138, 114, 109, 138, 1, 388, 1, 1, 111, 605, 1, 602, 120, 1, 1, 1, 5, 1, 605, 1]\n",
      "[1, 1, 1, 1, 109, 36, 1, 1, 1, 1, 198, 1, 1, 1, 198, 1, 118, 1, 109, 198, 1]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sample larger than population or is negative",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\github\\MOERec\\test_main.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39mlocal_scope():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     graph\u001b[39m.\u001b[39;49mupdate_all(category_aggregation, sub_reduction_item_user, etype \u001b[39m=\u001b[39;49m etype)\n",
      "File \u001b[1;32mc:\\Users\\yuki_younai\\.conda\\envs\\PyTorch\\lib\\site-packages\\dgl\\heterograph.py:5110\u001b[0m, in \u001b[0;36mDGLGraph.update_all\u001b[1;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[0;32m   5108\u001b[0m _, dtid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39mmetagraph\u001b[39m.\u001b[39mfind_edge(etid)\n\u001b[0;32m   5109\u001b[0m g \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m etype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m[etype]\n\u001b[1;32m-> 5110\u001b[0m ndata \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39;49mmessage_passing(\n\u001b[0;32m   5111\u001b[0m     g, message_func, reduce_func, apply_node_func\n\u001b[0;32m   5112\u001b[0m )\n\u001b[0;32m   5113\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5114\u001b[0m     core\u001b[39m.\u001b[39mis_builtin(reduce_func)\n\u001b[0;32m   5115\u001b[0m     \u001b[39mand\u001b[39;00m reduce_func\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   5116\u001b[0m     \u001b[39mand\u001b[39;00m ndata\n\u001b[0;32m   5117\u001b[0m ):\n\u001b[0;32m   5118\u001b[0m     \u001b[39m# Replace infinity with zero for isolated nodes\u001b[39;00m\n\u001b[0;32m   5119\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ndata\u001b[39m.\u001b[39mkeys())[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\yuki_younai\\.conda\\envs\\PyTorch\\lib\\site-packages\\dgl\\core.py:405\u001b[0m, in \u001b[0;36mmessage_passing\u001b[1;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m         orig_nid \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39mdstdata\u001b[39m.\u001b[39mget(NID, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 405\u001b[0m         ndata \u001b[39m=\u001b[39m invoke_udf_reduce(g, rfunc, msgdata, orig_nid\u001b[39m=\u001b[39;49morig_nid)\n\u001b[0;32m    406\u001b[0m \u001b[39m# apply phase\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[39mif\u001b[39;00m afunc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\yuki_younai\\.conda\\envs\\PyTorch\\lib\\site-packages\\dgl\\core.py:157\u001b[0m, in \u001b[0;36minvoke_udf_reduce\u001b[1;34m(graph, func, msgdata, orig_nid)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[39m# invoke udf\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     nbatch \u001b[39m=\u001b[39m NodeBatch(graph, orig_nid_bkt, ntype, ndata_bkt, msgs\u001b[39m=\u001b[39mmaildata)\n\u001b[1;32m--> 157\u001b[0m     bkt_rsts\u001b[39m.\u001b[39mappend(func(nbatch))\n\u001b[0;32m    159\u001b[0m \u001b[39m# prepare a result frame\u001b[39;00m\n\u001b[0;32m    160\u001b[0m retf \u001b[39m=\u001b[39m Frame(num_rows\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(nodes))\n",
      "\u001b[1;32md:\\code\\github\\MOERec\\test_main.ipynb Cell 8\u001b[0m in \u001b[0;36msub_reduction_item_user\u001b[1;34m(nodes)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     cat\u001b[39m=\u001b[39mnodes\u001b[39m.\u001b[39mmailbox[\u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     neighbors\u001b[39m=\u001b[39msubmodular_selection_feature(nodes)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     mail \u001b[39m=\u001b[39m mail[torch\u001b[39m.\u001b[39marange(batch_size, dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlong, device \u001b[39m=\u001b[39m mail\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), neighbors]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     mail\u001b[39m=\u001b[39mmail\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32md:\\code\\github\\MOERec\\test_main.ipynb Cell 8\u001b[0m in \u001b[0;36msubmodular_selection_feature\u001b[1;34m(nodes)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m sorted_indices:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m    my_list\u001b[39m=\u001b[39melement_indices[unique_elements[i]]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m    random_elements\u001b[39m=\u001b[39mrandom\u001b[39m.\u001b[39;49msample(my_list, k\u001b[39m=\u001b[39;49mcat_number[i])\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m    select\u001b[39m=\u001b[39mselect\u001b[39m+\u001b[39mrandom_elements\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m    \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(select)\u001b[39m>\u001b[39m\u001b[39m=\u001b[39mmaxlen:\n",
      "File \u001b[1;32mc:\\Users\\yuki_younai\\.conda\\envs\\PyTorch\\lib\\random.py:363\u001b[0m, in \u001b[0;36mRandom.sample\u001b[1;34m(self, population, k)\u001b[0m\n\u001b[0;32m    361\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(population)\n\u001b[0;32m    362\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m k \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m n:\n\u001b[1;32m--> 363\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mSample larger than population or is negative\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    364\u001b[0m result \u001b[39m=\u001b[39m [\u001b[39mNone\u001b[39;00m] \u001b[39m*\u001b[39m k\n\u001b[0;32m    365\u001b[0m setsize \u001b[39m=\u001b[39m \u001b[39m21\u001b[39m        \u001b[39m# size of a small set minus size of an empty list\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Sample larger than population or is negative"
     ]
    }
   ],
   "source": [
    "with graph.local_scope():\n",
    "    graph.update_all(category_aggregation, sub_reduction_item_user, etype = etype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
