{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "from utils.parser import parse_args\n",
    "from utils.dataloader import Dataloader\n",
    "from utils.utils import config, construct_negative_graph, choose_model, load_mf_model, NegativeGraph\n",
    "from utils.tester import Tester\n",
    "from models.sampler import NegativeSampler\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', default = 'TaoBao', type = str,\n",
    "                    help = 'Dataset to use')\n",
    "parser.add_argument('--seed', default = 2022, type = int,\n",
    "                    help = 'seed for experiment')\n",
    "parser.add_argument('--embed_size', default = 32, type = int,\n",
    "                    help = 'embedding size for all layer')\n",
    "parser.add_argument('--lr', default = 0.05, type = float,\n",
    "                    help = 'learning rate')\n",
    "parser.add_argument('--weight_decay', default = 8e-8, type = float,\n",
    "                    help = \"weight decay for adam optimizer\")\n",
    "#######################################################################\n",
    "parser.add_argument('--model', default ='test',type = str,\n",
    "                    help = 'model selection')#dgrec base moe test\n",
    "parser.add_argument('--epoch', default = 1000, type = int,\n",
    "                    help = 'epoch number')\n",
    "parser.add_argument('--patience', default = 10, type = int,\n",
    "                    help = 'early_stop validation')\n",
    "parser.add_argument('--batch_size', default = 2048, type = int,\n",
    "                    help = 'batch size')\n",
    "parser.add_argument('--layers', default = 1, type = int,\n",
    "                    help = 'layer number')\n",
    "parser.add_argument('--gpu', default = 0, type = int,\n",
    "                    help = '-1 for cpu, 0 for gpu:0')\n",
    "parser.add_argument('--k_list', default = [100, 300], type = list,\n",
    "                    help = 'topk evaluation')\n",
    "parser.add_argument('--k', default = 20, type = int,\n",
    "                    help = 'neighbor number in each GNN aggregation')\n",
    "parser.add_argument('--neg_number', default = 4, type = int,\n",
    "                    help = 'negative sampler number for each positive pair')\n",
    "parser.add_argument('--metrics', default = ['recall', 'hit_ratio', 'coverage'])\n",
    "\n",
    "\n",
    "parser.add_argument('--sigma', default = 1.0, type = float,\n",
    "                    help = 'sigma for gaussian kernel')\n",
    "parser.add_argument('--gamma', default = 2.0, type = float,\n",
    "                    help = 'gamma for gaussian kernel')\n",
    "################################################################################\n",
    "parser.add_argument('--category_balance', default = True, type = bool,\n",
    "                    help = 'whether make loss category balance')\n",
    "parser.add_argument('--beta_class', default = 0.9, type = float,\n",
    "                    help = 'class re-balanced loss beta')\n",
    "parser.add_argument('--context_code_dim', default = 32, type = int,\n",
    "                    help = 'interest num')\n",
    "parser.add_argument('--num_context_codes', default = 32, type = int,\n",
    "                    help = 'interest dim')\n",
    "parser.add_argument('--n_experts', default = 5, type = int,\n",
    "                    help = 'n_experts')\n",
    "##########################################################################################\n",
    "parser.add_argument('--wandb_enable', default = True, type = bool,\n",
    "                    help = 'layer number')\n",
    "parser.add_argument('--hidden_size', default = 32, type = int,\n",
    "                        help = 'n_experts')\n",
    "parser.add_argument('--k_experts', default = 2, type = int,\n",
    "                            help = 'n_experts')\n",
    "parser.add_argument('--moe', default = False, type = bool,\n",
    "                            help = 'layer number')\n",
    "################################################################################\n",
    "parser.add_argument('--sub', default = 'rand', type = str,\n",
    "                            help = 'layer number')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136710/136710 [00:07<00:00, 18612.94it/s]\n",
      "100%|██████████| 2571752/2571752 [00:03<00:00, 752442.68it/s] \n",
      "100%|██████████| 845781/845781 [00:01<00:00, 815638.97it/s] \n",
      "100%|██████████| 136710/136710 [00:00<00:00, 4170387.80it/s]\n"
     ]
    }
   ],
   "source": [
    "data = args.dataset\n",
    "if args.gpu >= 0 and torch.cuda.is_available():\n",
    "        device = 'cuda:{}'.format(args.gpu)\n",
    "else:\n",
    "        device = 'cpu'\n",
    "device = torch.device(device)\n",
    "args.device = device\n",
    "dataloader = Dataloader(args, data, device)\n",
    "graph = dataloader.train_graph\n",
    "\n",
    "hid_dim = args.embed_size\n",
    "user_embedding = torch.nn.Parameter(torch.randn(graph.nodes('user').shape[0], hid_dim))\n",
    "item_embedding = torch.nn.Parameter(torch.randn(graph.nodes('item').shape[0], hid_dim))\n",
    "node_features = {'user': user_embedding, 'item': item_embedding}\n",
    "etype=('item', 'rated by', 'user')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dataloader.train_graph\n",
    "feat_src = node_features['item'].to(device)\n",
    "graph.nodes['item'].data['h'] = feat_src\n",
    "cata_num=dataloader.category_num\n",
    "cata_embedding = torch.nn.Parameter(torch.randn(cata_num, 32)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "maxlen=20\n",
    "def cate_topsis(numbers):\n",
    "        square_sum=math.sqrt(sum(i**2 for i in numbers))\n",
    "        numbers = [math.exp(x/square_sum) for x in numbers]\n",
    "        ma=max(numbers)\n",
    "        mi=0.5*min(numbers)\n",
    "        result=[(x-mi) /(ma-mi) for x in numbers]\n",
    "        result = [x / sum(result) for x in result]\n",
    "        result=[math.ceil(x*maxlen) for x in result]\n",
    "        return result\n",
    "def submodular_selection_feature(nodes):\n",
    "        device = nodes.mailbox['m'].device\n",
    "        mail = nodes.mailbox['m']\n",
    "        batch_size, neighbor_size, feature_size = mail.shape\n",
    "        cat=nodes.mailbox['c']\n",
    "        user_select=[]\n",
    "        for i in range(batch_size):\n",
    "            select=[]\n",
    "            line=cat[i].reshape(1,-1)[0].tolist()\n",
    "            unique_elements = list(set(line))\n",
    "            element_counts = [line.count(element) for element in unique_elements]\n",
    "            \n",
    "            element_indices = {}\n",
    "            for index, element in enumerate(line):\n",
    "                if element in element_indices:\n",
    "                   element_indices[element].append(index)\n",
    "                else:\n",
    "                   element_indices[element] = [index]\n",
    "        \n",
    "            sorted_indices = sorted(range(len(element_counts)), key=lambda i: element_counts[i], reverse=True)\n",
    "            cat_number=cate_topsis(element_counts)\n",
    "            for i in sorted_indices:\n",
    "               my_list=element_indices[unique_elements[i]]\n",
    "               random_elements=random.choices(my_list, k=cat_number[i])\n",
    "               select=select+random_elements\n",
    "               if len(select)>=maxlen:\n",
    "                   break\n",
    "            if len(select)>=maxlen:\n",
    "                select=select[0:maxlen]\n",
    "            else:\n",
    "                select=select+select[0:maxlen-len(select)]\n",
    "            if(len(select)<20):\n",
    "                print(\"start\")    \n",
    "                print(line)\n",
    "                print(unique_elements)\n",
    "                print(element_counts)\n",
    "                print(sorted_indices)\n",
    "                print(cat_number)\n",
    "                print(select)\n",
    "                print(\"end\")\n",
    "            user_select.append(select)\n",
    "        #print(user_select.shape)\n",
    "        user_select=torch.tensor(user_select)\n",
    "        \n",
    "\n",
    "        return user_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "def pairwise_cosine_similarity(x, y, zero_diagonal: bool = False):\n",
    "    r\"\"\"\n",
    "    Calculates the pairwise cosine similarity matrix\n",
    "\n",
    "    Args:\n",
    "        x: tensor of shape ``(batch_size, M, d)``\n",
    "        y: tensor of shape ``(batch_size, N, d)``\n",
    "        zero_diagonal: determines if the diagonal of the distance matrix should be set to zero\n",
    "\n",
    "    Returns:\n",
    "        A tensor of shape ``(batch_size, M, N)``\n",
    "    \"\"\"\n",
    "    x_norm = torch.linalg.norm(x, dim=2, keepdim=True)\n",
    "    y_norm = torch.linalg.norm(y, dim=2, keepdim=True)\n",
    "    distance = torch.matmul(torch.div(x, x_norm), torch.div(y, y_norm).permute(0, 2, 1))\n",
    "    \n",
    "\n",
    "    return distance\n",
    "def submodular_selection_randn(nodes):\n",
    "        \n",
    "        mail = nodes.mailbox['m']\n",
    "        batch_size, neighbor_size, feature_size = mail.shape\n",
    "        neighbor=torch.randint(neighbor_size,[0])\n",
    "        for i in range(batch_size):\n",
    "            item_select=torch.randint(neighbor_size,[1,20])\n",
    "            neighbor=torch.cat([neighbor,item_select],dim=0)\n",
    "\n",
    "        return neighbor\n",
    "def category_aggregation(edges):\n",
    "        return {'c': edges.src['category'], 'm': edges.src['h']}\n",
    "def sub_reduction_item_user(nodes):\n",
    "        # -1 indicate user-> node, which does not include category information\n",
    "        device = nodes.mailbox['m'].device\n",
    "        mail = nodes.mailbox['m']\n",
    "        cat=nodes.mailbox['c']\n",
    "        cat_emb=cata_embedding[torch.squeeze(cat,dim=2).to(device)]\n",
    "        \n",
    "        batch_size, neighbor_size, feature_size = mail.shape\n",
    "        if (-1 in nodes.mailbox['c']) or nodes.mailbox['m'].shape[1] <=20:\n",
    "            mail=mail.sum(dim=1)\n",
    "        else:\n",
    "            neighbors =submodular_selection_randn(nodes)\n",
    "            mail = mail[torch.arange(batch_size, dtype = torch.long, device = mail.device).unsqueeze(-1), neighbors]\n",
    "            cat_emb=cat_emb[torch.arange(batch_size, dtype = torch.long, device = mail.device).unsqueeze(-1), neighbors]\n",
    "            bias=pairwise_cosine_similarity(cat_emb,cat_emb)\n",
    "            print(cat_emb.shape)\n",
    "            \n",
    "            mail=mail.sum(dim=1)\n",
    "\n",
    "       \n",
    "    \n",
    "        return {'h': mail}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2237, 20, 32])\n",
      "torch.Size([1087, 20, 32])\n",
      "torch.Size([2212, 20, 32])\n",
      "torch.Size([1934, 20, 32])\n",
      "torch.Size([907, 20, 32])\n",
      "torch.Size([1748, 20, 32])\n",
      "torch.Size([1721, 20, 32])\n",
      "torch.Size([833, 20, 32])\n",
      "torch.Size([1549, 20, 32])\n",
      "torch.Size([1548, 20, 32])\n",
      "torch.Size([680, 20, 32])\n",
      "torch.Size([1332, 20, 32])\n",
      "torch.Size([1346, 20, 32])\n",
      "torch.Size([629, 20, 32])\n",
      "torch.Size([1262, 20, 32])\n",
      "torch.Size([1190, 20, 32])\n",
      "torch.Size([577, 20, 32])\n",
      "torch.Size([1093, 20, 32])\n",
      "torch.Size([1084, 20, 32])\n",
      "torch.Size([490, 20, 32])\n",
      "torch.Size([984, 20, 32])\n",
      "torch.Size([919, 20, 32])\n",
      "torch.Size([453, 20, 32])\n",
      "torch.Size([824, 20, 32])\n",
      "torch.Size([832, 20, 32])\n",
      "torch.Size([402, 20, 32])\n",
      "torch.Size([744, 20, 32])\n",
      "torch.Size([691, 20, 32])\n",
      "torch.Size([324, 20, 32])\n",
      "torch.Size([673, 20, 32])\n",
      "torch.Size([641, 20, 32])\n",
      "torch.Size([273, 20, 32])\n",
      "torch.Size([587, 20, 32])\n",
      "torch.Size([641, 20, 32])\n",
      "torch.Size([255, 20, 32])\n",
      "torch.Size([548, 20, 32])\n",
      "torch.Size([498, 20, 32])\n",
      "torch.Size([251, 20, 32])\n",
      "torch.Size([527, 20, 32])\n",
      "torch.Size([460, 20, 32])\n",
      "torch.Size([224, 20, 32])\n",
      "torch.Size([408, 20, 32])\n",
      "torch.Size([398, 20, 32])\n",
      "torch.Size([203, 20, 32])\n",
      "torch.Size([345, 20, 32])\n",
      "torch.Size([358, 20, 32])\n",
      "torch.Size([177, 20, 32])\n",
      "torch.Size([354, 20, 32])\n",
      "torch.Size([316, 20, 32])\n",
      "torch.Size([156, 20, 32])\n",
      "torch.Size([290, 20, 32])\n",
      "torch.Size([292, 20, 32])\n",
      "torch.Size([132, 20, 32])\n",
      "torch.Size([257, 20, 32])\n",
      "torch.Size([271, 20, 32])\n",
      "torch.Size([116, 20, 32])\n",
      "torch.Size([255, 20, 32])\n",
      "torch.Size([242, 20, 32])\n",
      "torch.Size([111, 20, 32])\n",
      "torch.Size([201, 20, 32])\n",
      "torch.Size([208, 20, 32])\n",
      "torch.Size([95, 20, 32])\n",
      "torch.Size([175, 20, 32])\n",
      "torch.Size([163, 20, 32])\n",
      "torch.Size([81, 20, 32])\n",
      "torch.Size([191, 20, 32])\n",
      "torch.Size([165, 20, 32])\n",
      "torch.Size([90, 20, 32])\n",
      "torch.Size([145, 20, 32])\n",
      "torch.Size([155, 20, 32])\n",
      "torch.Size([73, 20, 32])\n",
      "torch.Size([131, 20, 32])\n",
      "torch.Size([134, 20, 32])\n",
      "torch.Size([78, 20, 32])\n",
      "torch.Size([124, 20, 32])\n",
      "torch.Size([82, 20, 32])\n",
      "torch.Size([45, 20, 32])\n",
      "torch.Size([122, 20, 32])\n",
      "torch.Size([99, 20, 32])\n",
      "torch.Size([50, 20, 32])\n",
      "torch.Size([101, 20, 32])\n",
      "torch.Size([91, 20, 32])\n",
      "torch.Size([40, 20, 32])\n",
      "torch.Size([72, 20, 32])\n",
      "torch.Size([80, 20, 32])\n",
      "torch.Size([38, 20, 32])\n",
      "torch.Size([81, 20, 32])\n",
      "torch.Size([48, 20, 32])\n",
      "torch.Size([31, 20, 32])\n",
      "torch.Size([69, 20, 32])\n",
      "torch.Size([66, 20, 32])\n",
      "torch.Size([33, 20, 32])\n",
      "torch.Size([52, 20, 32])\n",
      "torch.Size([64, 20, 32])\n",
      "torch.Size([25, 20, 32])\n",
      "torch.Size([51, 20, 32])\n",
      "torch.Size([45, 20, 32])\n",
      "torch.Size([20, 20, 32])\n",
      "torch.Size([40, 20, 32])\n",
      "torch.Size([29, 20, 32])\n",
      "torch.Size([23, 20, 32])\n",
      "torch.Size([34, 20, 32])\n",
      "torch.Size([40, 20, 32])\n",
      "torch.Size([16, 20, 32])\n",
      "torch.Size([37, 20, 32])\n",
      "torch.Size([27, 20, 32])\n",
      "torch.Size([12, 20, 32])\n",
      "torch.Size([21, 20, 32])\n",
      "torch.Size([28, 20, 32])\n",
      "torch.Size([18, 20, 32])\n",
      "torch.Size([30, 20, 32])\n",
      "torch.Size([20, 20, 32])\n",
      "torch.Size([12, 20, 32])\n",
      "torch.Size([21, 20, 32])\n",
      "torch.Size([29, 20, 32])\n",
      "torch.Size([13, 20, 32])\n",
      "torch.Size([15, 20, 32])\n",
      "torch.Size([20, 20, 32])\n",
      "torch.Size([10, 20, 32])\n",
      "torch.Size([26, 20, 32])\n",
      "torch.Size([17, 20, 32])\n",
      "torch.Size([9, 20, 32])\n",
      "torch.Size([8, 20, 32])\n",
      "torch.Size([23, 20, 32])\n",
      "torch.Size([6, 20, 32])\n",
      "torch.Size([13, 20, 32])\n",
      "torch.Size([17, 20, 32])\n",
      "torch.Size([7, 20, 32])\n",
      "torch.Size([12, 20, 32])\n",
      "torch.Size([7, 20, 32])\n",
      "torch.Size([7, 20, 32])\n",
      "torch.Size([10, 20, 32])\n",
      "torch.Size([11, 20, 32])\n",
      "torch.Size([4, 20, 32])\n",
      "torch.Size([6, 20, 32])\n",
      "torch.Size([9, 20, 32])\n",
      "torch.Size([5, 20, 32])\n",
      "torch.Size([10, 20, 32])\n",
      "torch.Size([13, 20, 32])\n",
      "torch.Size([2, 20, 32])\n",
      "torch.Size([2, 20, 32])\n",
      "torch.Size([2, 20, 32])\n",
      "torch.Size([2, 20, 32])\n",
      "torch.Size([5, 20, 32])\n",
      "torch.Size([6, 20, 32])\n",
      "torch.Size([2, 20, 32])\n",
      "torch.Size([2, 20, 32])\n",
      "torch.Size([3, 20, 32])\n",
      "torch.Size([2, 20, 32])\n",
      "torch.Size([3, 20, 32])\n",
      "torch.Size([3, 20, 32])\n",
      "torch.Size([5, 20, 32])\n",
      "torch.Size([5, 20, 32])\n",
      "torch.Size([5, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([4, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([3, 20, 32])\n",
      "torch.Size([2, 20, 32])\n",
      "torch.Size([5, 20, 32])\n",
      "torch.Size([3, 20, 32])\n",
      "torch.Size([2, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([2, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([4, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([2, 20, 32])\n",
      "torch.Size([2, 20, 32])\n",
      "torch.Size([3, 20, 32])\n",
      "torch.Size([7, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([2, 20, 32])\n",
      "torch.Size([2, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([2, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([1, 20, 32])\n",
      "torch.Size([1, 20, 32])\n"
     ]
    }
   ],
   "source": [
    "with graph.local_scope():\n",
    "    graph.update_all(category_aggregation, sub_reduction_item_user, etype = etype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.4066e+00, -1.3300e+00,  2.0119e+00, -2.0197e+00, -1.0050e+00,\n",
       "           3.2687e-01,  4.3971e-01, -1.5703e+00,  1.2183e+00, -4.9825e-01,\n",
       "          -2.7870e-01, -4.0875e-01, -7.0351e-01, -1.2346e-01,  1.0357e+00,\n",
       "          -1.5857e+00,  6.0278e-01,  2.8883e+00, -1.0026e-01,  1.0496e-01,\n",
       "          -1.5525e+00, -3.4744e-01, -6.6411e-02, -7.5969e-01, -2.6731e-01,\n",
       "          -7.0714e-01, -8.9049e-01, -1.0908e+00, -1.0498e+00,  1.0004e+00,\n",
       "           6.5227e-01,  1.5745e+00],\n",
       "         [-1.7382e+00, -7.9115e-03, -3.3640e-02,  8.7213e-01, -9.3560e-01,\n",
       "          -8.7332e-01,  1.4803e+00, -1.3726e+00,  7.8083e-03, -1.3623e+00,\n",
       "          -2.8310e-01, -5.0738e-01, -1.3752e+00, -1.2206e+00, -3.6263e-01,\n",
       "           8.5177e-01,  1.8989e-01, -1.0751e+00, -7.7584e-02,  2.3632e-03,\n",
       "          -9.4927e-02, -4.8747e-02, -2.2387e-01,  6.4526e-02, -4.7183e-01,\n",
       "          -8.6214e-01,  5.1349e-01,  1.1047e+00,  5.9435e-01,  1.8810e+00,\n",
       "           1.4664e+00,  4.0705e-01],\n",
       "         [-2.1008e+00, -7.2216e-01, -1.3661e+00, -3.7395e-01, -5.1018e-01,\n",
       "          -1.7279e+00,  7.7139e-01, -6.8610e-01,  1.0568e+00, -1.6433e+00,\n",
       "          -8.0969e-02,  1.0137e-01, -1.0150e+00,  1.6541e+00,  7.8065e-02,\n",
       "          -4.1456e-01, -1.3670e+00,  5.4848e-01,  7.8730e-01, -6.7058e-01,\n",
       "           1.7205e+00, -3.9041e-01, -2.2856e+00, -2.6211e-01,  5.8705e-01,\n",
       "          -1.3649e-01,  4.5928e-01, -1.8707e+00,  1.0807e+00,  6.1788e-01,\n",
       "          -5.8952e-01,  5.0526e-01]],\n",
       "\n",
       "        [[-1.7382e+00, -7.9115e-03, -3.3640e-02,  8.7213e-01, -9.3560e-01,\n",
       "          -8.7332e-01,  1.4803e+00, -1.3726e+00,  7.8083e-03, -1.3623e+00,\n",
       "          -2.8310e-01, -5.0738e-01, -1.3752e+00, -1.2206e+00, -3.6263e-01,\n",
       "           8.5177e-01,  1.8989e-01, -1.0751e+00, -7.7584e-02,  2.3632e-03,\n",
       "          -9.4927e-02, -4.8747e-02, -2.2387e-01,  6.4526e-02, -4.7183e-01,\n",
       "          -8.6214e-01,  5.1349e-01,  1.1047e+00,  5.9435e-01,  1.8810e+00,\n",
       "           1.4664e+00,  4.0705e-01],\n",
       "         [-2.1008e+00, -7.2216e-01, -1.3661e+00, -3.7395e-01, -5.1018e-01,\n",
       "          -1.7279e+00,  7.7139e-01, -6.8610e-01,  1.0568e+00, -1.6433e+00,\n",
       "          -8.0969e-02,  1.0137e-01, -1.0150e+00,  1.6541e+00,  7.8065e-02,\n",
       "          -4.1456e-01, -1.3670e+00,  5.4848e-01,  7.8730e-01, -6.7058e-01,\n",
       "           1.7205e+00, -3.9041e-01, -2.2856e+00, -2.6211e-01,  5.8705e-01,\n",
       "          -1.3649e-01,  4.5928e-01, -1.8707e+00,  1.0807e+00,  6.1788e-01,\n",
       "          -5.8952e-01,  5.0526e-01],\n",
       "         [-8.5695e-03, -5.5739e-01, -3.8741e-01,  1.6863e+00, -3.0719e-01,\n",
       "           2.5748e-01, -1.6304e+00, -7.2671e-01, -3.0463e-01, -9.1748e-01,\n",
       "          -1.7838e+00, -1.0011e+00,  1.8703e-01, -1.1727e+00,  1.3114e+00,\n",
       "          -1.0624e+00, -8.3977e-01,  4.9143e-01, -1.1712e+00,  1.2239e-01,\n",
       "          -5.5742e-01, -1.0556e+00, -5.9214e-01, -5.9328e-01,  1.9319e+00,\n",
       "          -1.5957e+00,  1.5315e+00, -5.5498e-01,  8.0556e-01, -1.1981e+00,\n",
       "          -4.3015e-01,  2.0084e+00]]], grad_fn=<IndexBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=torch.tensor([[1,3,4],[3,4,5]])\n",
    "cata_embedding[x]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
