{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "from utils.parser import parse_args\n",
    "from utils.dataloader import Dataloader\n",
    "from utils.utils import config, construct_negative_graph, choose_model, load_mf_model, NegativeGraph\n",
    "from utils.tester import Tester\n",
    "from models.sampler import NegativeSampler\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', default = 'TaoBao', type = str,\n",
    "                    help = 'Dataset to use')\n",
    "parser.add_argument('--seed', default = 2022, type = int,\n",
    "                    help = 'seed for experiment')\n",
    "parser.add_argument('--embed_size', default = 32, type = int,\n",
    "                    help = 'embedding size for all layer')\n",
    "parser.add_argument('--lr', default = 0.05, type = float,\n",
    "                    help = 'learning rate')\n",
    "parser.add_argument('--weight_decay', default = 8e-8, type = float,\n",
    "                    help = \"weight decay for adam optimizer\")\n",
    "#######################################################################\n",
    "parser.add_argument('--model', default ='test',type = str,\n",
    "                    help = 'model selection')#dgrec base moe test\n",
    "parser.add_argument('--epoch', default = 1000, type = int,\n",
    "                    help = 'epoch number')\n",
    "parser.add_argument('--patience', default = 10, type = int,\n",
    "                    help = 'early_stop validation')\n",
    "parser.add_argument('--batch_size', default = 2048, type = int,\n",
    "                    help = 'batch size')\n",
    "parser.add_argument('--layers', default = 1, type = int,\n",
    "                    help = 'layer number')\n",
    "parser.add_argument('--gpu', default = 0, type = int,\n",
    "                    help = '-1 for cpu, 0 for gpu:0')\n",
    "parser.add_argument('--k_list', default = [100, 300], type = list,\n",
    "                    help = 'topk evaluation')\n",
    "parser.add_argument('--k', default = 20, type = int,\n",
    "                    help = 'neighbor number in each GNN aggregation')\n",
    "parser.add_argument('--neg_number', default = 4, type = int,\n",
    "                    help = 'negative sampler number for each positive pair')\n",
    "parser.add_argument('--metrics', default = ['recall', 'hit_ratio', 'coverage'])\n",
    "\n",
    "\n",
    "parser.add_argument('--sigma', default = 1.0, type = float,\n",
    "                    help = 'sigma for gaussian kernel')\n",
    "parser.add_argument('--gamma', default = 2.0, type = float,\n",
    "                    help = 'gamma for gaussian kernel')\n",
    "################################################################################\n",
    "parser.add_argument('--category_balance', default = True, type = bool,\n",
    "                    help = 'whether make loss category balance')\n",
    "parser.add_argument('--beta_class', default = 0.9, type = float,\n",
    "                    help = 'class re-balanced loss beta')\n",
    "parser.add_argument('--context_code_dim', default = 32, type = int,\n",
    "                    help = 'interest num')\n",
    "parser.add_argument('--num_context_codes', default = 32, type = int,\n",
    "                    help = 'interest dim')\n",
    "parser.add_argument('--n_experts', default = 5, type = int,\n",
    "                    help = 'n_experts')\n",
    "##########################################################################################\n",
    "parser.add_argument('--wandb_enable', default = True, type = bool,\n",
    "                    help = 'layer number')\n",
    "parser.add_argument('--hidden_size', default = 32, type = int,\n",
    "                        help = 'n_experts')\n",
    "parser.add_argument('--k_experts', default = 2, type = int,\n",
    "                            help = 'n_experts')\n",
    "parser.add_argument('--moe', default = False, type = bool,\n",
    "                            help = 'layer number')\n",
    "################################################################################\n",
    "parser.add_argument('--sub', default = 'rand', type = str,\n",
    "                            help = 'layer number')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136710/136710 [00:07<00:00, 18371.36it/s]\n",
      "100%|██████████| 2571752/2571752 [00:03<00:00, 756702.36it/s] \n",
      "100%|██████████| 845781/845781 [00:01<00:00, 790251.49it/s] \n",
      "100%|██████████| 136710/136710 [00:00<00:00, 3562661.85it/s]\n"
     ]
    }
   ],
   "source": [
    "data = args.dataset\n",
    "if args.gpu >= 0 and torch.cuda.is_available():\n",
    "        device = 'cuda:{}'.format(args.gpu)\n",
    "else:\n",
    "        device = 'cpu'\n",
    "device = torch.device(device)\n",
    "args.device = device\n",
    "dataloader = Dataloader(args, data, device)\n",
    "graph = dataloader.train_graph\n",
    "\n",
    "hid_dim = args.embed_size\n",
    "user_embedding = torch.nn.Parameter(torch.randn(graph.nodes('user').shape[0], hid_dim))\n",
    "item_embedding = torch.nn.Parameter(torch.randn(graph.nodes('item').shape[0], hid_dim))\n",
    "node_features = {'user': user_embedding, 'item': item_embedding}\n",
    "etype=('item', 'rated by', 'user')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dataloader.train_graph\n",
    "feat_src = node_features['item'].to(device)\n",
    "graph.nodes['item'].data['h'] = feat_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import random\n",
    "maxlen=20\n",
    "def cate_topsis(numbers):\n",
    "        square_sum=math.sqrt(sum(i**2 for i in numbers))\n",
    "        numbers = [math.exp(x/square_sum) for x in numbers]\n",
    "        ma=max(numbers)\n",
    "        mi=0.5*min(numbers)\n",
    "        result=[(x-mi) /(ma-mi) for x in numbers]\n",
    "        result = [x / sum(result) for x in result]\n",
    "        result=[math.ceil(x*maxlen) for x in result]\n",
    "        return result\n",
    "def submodular_selection_feature(nodes):\n",
    "        device = nodes.mailbox['m'].device\n",
    "        mail = nodes.mailbox['m']\n",
    "        batch_size, neighbor_size, feature_size = mail.shape\n",
    "        cat=nodes.mailbox['c']\n",
    "        user_select=[]\n",
    "        for i in range(batch_size):\n",
    "            select=[]\n",
    "            line=cat[i].reshape(1,-1)[0].tolist()\n",
    "            unique_elements = list(set(line))\n",
    "            element_counts = [line.count(element) for element in unique_elements]\n",
    "            \n",
    "            element_indices = {}\n",
    "            for index, element in enumerate(line):\n",
    "                if element in element_indices:\n",
    "                   element_indices[element].append(index)\n",
    "                else:\n",
    "                   element_indices[element] = [index]\n",
    "        \n",
    "            sorted_indices = sorted(range(len(element_counts)), key=lambda i: element_counts[i], reverse=True)\n",
    "            cat_number=cate_topsis(element_counts)\n",
    "            for i in sorted_indices:\n",
    "               my_list=element_indices[unique_elements[i]]\n",
    "               random_elements=random.choices(my_list, k=cat_number[i])\n",
    "               select=select+random_elements\n",
    "               if len(select)>=maxlen:\n",
    "                   break\n",
    "            if len(select)>=maxlen:\n",
    "                select=select[0:maxlen]\n",
    "            else:\n",
    "                select=select+select[0:maxlen-len(select)]\n",
    "            if(len(select)<20):\n",
    "                print(\"start\")    \n",
    "                print(line)\n",
    "                print(unique_elements)\n",
    "                print(element_counts)\n",
    "                print(sorted_indices)\n",
    "                print(cat_number)\n",
    "                print(select)\n",
    "                print(\"end\")\n",
    "            user_select.append(select)\n",
    "        #print(user_select.shape)\n",
    "        user_select=torch.tensor(user_select)\n",
    "        \n",
    "\n",
    "        return user_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "\n",
    "def category_aggregation(edges):\n",
    "        return {'c': edges.src['category'], 'm': edges.src['h']}\n",
    "def sub_reduction_item_user(nodes):\n",
    "        # -1 indicate user-> node, which does not include category information\n",
    "        mail = nodes.mailbox['m']\n",
    "        batch_size, neighbor_size, feature_size = mail.shape\n",
    "                  \n",
    "    \n",
    "        if (-1 in nodes.mailbox['c']) or nodes.mailbox['m'].shape[1] <=20:\n",
    "            \n",
    "            mail=mail.sum(dim=1)\n",
    "        else:\n",
    "            cat=nodes.mailbox['c']\n",
    "            \n",
    "            neighbors=submodular_selection_feature(nodes)\n",
    "            mail = mail[torch.arange(batch_size, dtype = torch.long, device = mail.device).unsqueeze(-1), neighbors]\n",
    "            mail=mail.sum(dim=1)\n",
    "        \n",
    "        return {'h': mail}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start\n",
      "[453, 233, 1290, 137, 43, 165, 241, 270, 1360, 109, 823, 341, 372, 111, 820, 1274, 114, 298, 762, 204, 183]\n",
      "[137, 1290, 1274, 270, 165, 298, 43, 820, 823, 183, 453, 204, 1360, 341, 233, 109, 111, 241, 114, 372, 762]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[]\n",
      "end\n",
      "start\n",
      "[118, 382, 1031, 160, 11, 1031, 830, 19, 40, 969, 36, 327, 799, 204, 432, 648, 267, 478, 147, 448, 213]\n",
      "[1031, 648, 11, 267, 19, 147, 799, 160, 36, 40, 432, 830, 448, 327, 969, 204, 213, 478, 118, 382]\n",
      "[2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[2, 2]\n",
      "end\n",
      "start\n",
      "[132, 109, 198, 126, 41, 43, 126, 119, 407, 385, 292, 36, 2, 76, 1473, 238, 215, 177, 694, 68, 23]\n",
      "[385, 2, 132, 407, 23, 292, 36, 41, 43, 177, 694, 1473, 68, 198, 76, 215, 109, 238, 119, 126]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2]\n",
      "[19, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1]\n",
      "[3, 3]\n",
      "end\n",
      "start\n",
      "[140, 180, 117, 1512, 1083, 1413, 995, 56, 154, 292, 2, 198, 393, 140, 25, 992, 537, 348, 49, 763, 988]\n",
      "[2, 1413, 393, 140, 537, 25, 154, 292, 49, 180, 56, 1083, 198, 348, 988, 992, 995, 1512, 117, 763]\n",
      "[1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[3, 0, 1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[0, 0]\n",
      "end\n",
      "start\n",
      "[178, 1074, 2310, 2204, 1356, 1333, 571, 1220, 1252, 1354, 1401, 1012, 1988, 949, 2372, 1863, 2292, 669, 1227, 1276, 1863]\n",
      "[2310, 2204, 669, 178, 1074, 1333, 949, 571, 1220, 1988, 2372, 1863, 1354, 1227, 1356, 1252, 1012, 2292, 1401, 1276]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[11, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[15, 15]\n",
      "end\n",
      "start\n",
      "[225, 160, 830, 1074, 637, 2600, 293, 41, 2657, 2415, 1747, 843, 832, 271, 2495, 2619, 2180, 662, 577, 1272, 170]\n",
      "[2180, 271, 662, 160, 293, 2600, 41, 170, 1074, 2619, 830, 2495, 832, 577, 843, 1747, 225, 2657, 2415, 1272, 637]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[]\n",
      "end\n",
      "start\n",
      "[49, 241, 668, 809, 901, 49, 638, 126, 1443, 334, 703, 2129, 2314, 820, 32, 2814, 198, 233, 921, 538, 771]\n",
      "[771, 901, 2314, 638, 921, 538, 668, 32, 1443, 809, 49, 820, 703, 198, 334, 2129, 233, 241, 126, 2814]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[5, 5]\n",
      "end\n",
      "start\n",
      "[482, 746, 755, 820, 594, 787, 874, 2435, 1155, 1865, 160, 2373, 2447, 505, 1063, 2450, 585, 1865, 475, 554, 604]\n",
      "[2435, 1155, 2447, 2450, 787, 160, 1063, 554, 820, 2373, 1865, 585, 594, 475, 604, 482, 746, 874, 755, 505]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[10, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[9, 9]\n",
      "end\n",
      "start\n",
      "[450, 11, 719, 1512, 217, 203, 673, 1253, 34, 112, 400, 703, 942, 637, 243, 1591, 49, 2, 762, 644, 1199]\n",
      "[2, 644, 11, 400, 673, 34, 942, 1199, 49, 1591, 703, 450, 203, 719, 217, 1253, 1512, 112, 243, 762, 637]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20]\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[]\n",
      "end\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "expected sequence of length 20 at dim 1 (got 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\github\\MOERec\\test_main.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39mlocal_scope():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     graph\u001b[39m.\u001b[39;49mupdate_all(category_aggregation, sub_reduction_item_user, etype \u001b[39m=\u001b[39;49m etype)\n",
      "File \u001b[1;32mc:\\Users\\yuki_younai\\.conda\\envs\\PyTorch\\lib\\site-packages\\dgl\\heterograph.py:5110\u001b[0m, in \u001b[0;36mDGLGraph.update_all\u001b[1;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[0;32m   5108\u001b[0m _, dtid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39mmetagraph\u001b[39m.\u001b[39mfind_edge(etid)\n\u001b[0;32m   5109\u001b[0m g \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m etype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m[etype]\n\u001b[1;32m-> 5110\u001b[0m ndata \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39;49mmessage_passing(\n\u001b[0;32m   5111\u001b[0m     g, message_func, reduce_func, apply_node_func\n\u001b[0;32m   5112\u001b[0m )\n\u001b[0;32m   5113\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5114\u001b[0m     core\u001b[39m.\u001b[39mis_builtin(reduce_func)\n\u001b[0;32m   5115\u001b[0m     \u001b[39mand\u001b[39;00m reduce_func\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   5116\u001b[0m     \u001b[39mand\u001b[39;00m ndata\n\u001b[0;32m   5117\u001b[0m ):\n\u001b[0;32m   5118\u001b[0m     \u001b[39m# Replace infinity with zero for isolated nodes\u001b[39;00m\n\u001b[0;32m   5119\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ndata\u001b[39m.\u001b[39mkeys())[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\yuki_younai\\.conda\\envs\\PyTorch\\lib\\site-packages\\dgl\\core.py:405\u001b[0m, in \u001b[0;36mmessage_passing\u001b[1;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m         orig_nid \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39mdstdata\u001b[39m.\u001b[39mget(NID, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 405\u001b[0m         ndata \u001b[39m=\u001b[39m invoke_udf_reduce(g, rfunc, msgdata, orig_nid\u001b[39m=\u001b[39;49morig_nid)\n\u001b[0;32m    406\u001b[0m \u001b[39m# apply phase\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[39mif\u001b[39;00m afunc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\yuki_younai\\.conda\\envs\\PyTorch\\lib\\site-packages\\dgl\\core.py:157\u001b[0m, in \u001b[0;36minvoke_udf_reduce\u001b[1;34m(graph, func, msgdata, orig_nid)\u001b[0m\n\u001b[0;32m    155\u001b[0m     \u001b[39m# invoke udf\u001b[39;00m\n\u001b[0;32m    156\u001b[0m     nbatch \u001b[39m=\u001b[39m NodeBatch(graph, orig_nid_bkt, ntype, ndata_bkt, msgs\u001b[39m=\u001b[39mmaildata)\n\u001b[1;32m--> 157\u001b[0m     bkt_rsts\u001b[39m.\u001b[39mappend(func(nbatch))\n\u001b[0;32m    159\u001b[0m \u001b[39m# prepare a result frame\u001b[39;00m\n\u001b[0;32m    160\u001b[0m retf \u001b[39m=\u001b[39m Frame(num_rows\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(nodes))\n",
      "\u001b[1;32md:\\code\\github\\MOERec\\test_main.ipynb Cell 8\u001b[0m in \u001b[0;36msub_reduction_item_user\u001b[1;34m(nodes)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m     cat\u001b[39m=\u001b[39mnodes\u001b[39m.\u001b[39mmailbox[\u001b[39m'\u001b[39m\u001b[39mc\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     neighbors\u001b[39m=\u001b[39msubmodular_selection_feature(nodes)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     mail \u001b[39m=\u001b[39m mail[torch\u001b[39m.\u001b[39marange(batch_size, dtype \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mlong, device \u001b[39m=\u001b[39m mail\u001b[39m.\u001b[39mdevice)\u001b[39m.\u001b[39munsqueeze(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m), neighbors]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     mail\u001b[39m=\u001b[39mmail\u001b[39m.\u001b[39msum(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
      "\u001b[1;32md:\\code\\github\\MOERec\\test_main.ipynb Cell 8\u001b[0m in \u001b[0;36msubmodular_selection_feature\u001b[1;34m(nodes)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=57'>58</a>\u001b[0m     user_select\u001b[39m.\u001b[39mappend(select)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=58'>59</a>\u001b[0m \u001b[39m#print(user_select.shape)\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=59'>60</a>\u001b[0m user_select\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39;49mtensor(user_select)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#X10sZmlsZQ%3D%3D?line=62'>63</a>\u001b[0m \u001b[39mreturn\u001b[39;00m user_select\n",
      "\u001b[1;31mValueError\u001b[0m: expected sequence of length 20 at dim 1 (got 0)"
     ]
    }
   ],
   "source": [
    "with graph.local_scope():\n",
    "    graph.update_all(category_aggregation, sub_reduction_item_user, etype = etype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 4, 5, 5, 3, 3]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.choices([1,3,4,5,3,1], k=6)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
