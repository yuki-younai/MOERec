{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import dgl\n",
    "import dgl.function as fn\n",
    "import os\n",
    "import multiprocessing as mp\n",
    "from tqdm import tqdm\n",
    "import pdb\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import logging\n",
    "from utils.parser import parse_args\n",
    "from utils.dataloader import Dataloader\n",
    "from utils.utils import config, construct_negative_graph, choose_model, load_mf_model, NegativeGraph\n",
    "from utils.tester import Tester\n",
    "from models.sampler import NegativeSampler\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument('--dataset', default = 'TaoBao', type = str,\n",
    "                    help = 'Dataset to use')\n",
    "parser.add_argument('--seed', default = 2022, type = int,\n",
    "                    help = 'seed for experiment')\n",
    "parser.add_argument('--embed_size', default = 32, type = int,\n",
    "                    help = 'embedding size for all layer')\n",
    "parser.add_argument('--lr', default = 0.05, type = float,\n",
    "                    help = 'learning rate')\n",
    "parser.add_argument('--weight_decay', default = 8e-8, type = float,\n",
    "                    help = \"weight decay for adam optimizer\")\n",
    "#######################################################################\n",
    "parser.add_argument('--model', default ='test',type = str,\n",
    "                    help = 'model selection')#dgrec base moe test\n",
    "parser.add_argument('--epoch', default = 1000, type = int,\n",
    "                    help = 'epoch number')\n",
    "parser.add_argument('--patience', default = 10, type = int,\n",
    "                    help = 'early_stop validation')\n",
    "parser.add_argument('--batch_size', default = 2048, type = int,\n",
    "                    help = 'batch size')\n",
    "parser.add_argument('--layers', default = 1, type = int,\n",
    "                    help = 'layer number')\n",
    "parser.add_argument('--gpu', default = 0, type = int,\n",
    "                    help = '-1 for cpu, 0 for gpu:0')\n",
    "parser.add_argument('--k_list', default = [100, 300], type = list,\n",
    "                    help = 'topk evaluation')\n",
    "parser.add_argument('--k', default = 20, type = int,\n",
    "                    help = 'neighbor number in each GNN aggregation')\n",
    "parser.add_argument('--neg_number', default = 4, type = int,\n",
    "                    help = 'negative sampler number for each positive pair')\n",
    "parser.add_argument('--metrics', default = ['recall', 'hit_ratio', 'coverage'])\n",
    "\n",
    "\n",
    "parser.add_argument('--sigma', default = 1.0, type = float,\n",
    "                    help = 'sigma for gaussian kernel')\n",
    "parser.add_argument('--gamma', default = 2.0, type = float,\n",
    "                    help = 'gamma for gaussian kernel')\n",
    "################################################################################\n",
    "parser.add_argument('--category_balance', default = True, type = bool,\n",
    "                    help = 'whether make loss category balance')\n",
    "parser.add_argument('--beta_class', default = 0.9, type = float,\n",
    "                    help = 'class re-balanced loss beta')\n",
    "parser.add_argument('--context_code_dim', default = 32, type = int,\n",
    "                    help = 'interest num')\n",
    "parser.add_argument('--num_context_codes', default = 32, type = int,\n",
    "                    help = 'interest dim')\n",
    "parser.add_argument('--n_experts', default = 5, type = int,\n",
    "                    help = 'n_experts')\n",
    "##########################################################################################\n",
    "parser.add_argument('--wandb_enable', default = True, type = bool,\n",
    "                    help = 'layer number')\n",
    "parser.add_argument('--hidden_size', default = 32, type = int,\n",
    "                        help = 'n_experts')\n",
    "parser.add_argument('--k_experts', default = 2, type = int,\n",
    "                            help = 'n_experts')\n",
    "parser.add_argument('--moe', default = False, type = bool,\n",
    "                            help = 'layer number')\n",
    "################################################################################\n",
    "parser.add_argument('--sub', default = 'rand', type = str,\n",
    "                            help = 'layer number')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 136710/136710 [00:07<00:00, 19456.90it/s]\n",
      "100%|██████████| 2571752/2571752 [00:03<00:00, 768836.54it/s]\n",
      "100%|██████████| 845781/845781 [00:00<00:00, 878513.19it/s] \n",
      "100%|██████████| 136710/136710 [00:00<00:00, 4557076.78it/s]\n"
     ]
    }
   ],
   "source": [
    "data = args.dataset\n",
    "if args.gpu >= 0 and torch.cuda.is_available():\n",
    "        device = 'cuda:{}'.format(args.gpu)\n",
    "else:\n",
    "        device = 'cpu'\n",
    "device = torch.device(device)\n",
    "args.device = device\n",
    "dataloader = Dataloader(args, data, device)\n",
    "graph = dataloader.train_graph\n",
    "\n",
    "hid_dim = args.embed_size\n",
    "user_embedding = torch.nn.Parameter(torch.randn(graph.nodes('user').shape[0], hid_dim))\n",
    "item_embedding = torch.nn.Parameter(torch.randn(graph.nodes('item').shape[0], hid_dim))\n",
    "node_features = {'user': user_embedding, 'item': item_embedding}\n",
    "etype=('item', 'rated by', 'user')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = dataloader.train_graph\n",
    "feat_src = node_features['item'].to(device)\n",
    "graph.nodes['item'].data['h'] = feat_src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_matrix(X, sigma = 1.0, gamma = 2.0):\n",
    "        dists = torch.cdist(X, X)\n",
    "        sims = torch.exp(-dists / (sigma * dists.mean(dim = -1).mean(dim = -1).reshape(-1, 1, 1)))\n",
    "        return sims\n",
    "import math\n",
    "import random\n",
    "maxlen=20\n",
    "def submodular_selection_feature(nodes):\n",
    "        device = nodes.mailbox['m'].device\n",
    "        mail = nodes.mailbox['m']\n",
    "        batch_size, neighbor_size, feature_size = mail.shape\n",
    "        cat=nodes.mailbox['c']\n",
    "        user_select=[]\n",
    "        for i in range(batch_size):\n",
    "            select=[]\n",
    "            line=cat[i].reshape(1,-1)[0].tolist()\n",
    "            unique_elements = list(set(line))\n",
    "            element_counts = [line.count(element) for element in unique_elements]\n",
    "            element_indices = {}\n",
    "            for index, element in enumerate(line):\n",
    "                if element in element_indices:\n",
    "                   element_indices[element].append(index)\n",
    "                else:\n",
    "                   element_indices[element] = [index]\n",
    "            avg=math.ceil(sum(element_counts)/len(element_counts))\n",
    "\n",
    "            sorted_indices = sorted(range(len(element_counts)), key=lambda i: element_counts[i], reverse=True)\n",
    "\n",
    "            for i in sorted_indices:\n",
    "               my_list=element_indices[unique_elements[i]]\n",
    "               if int(len(my_list)/2)>avg:\n",
    "                   random_elements = random.sample(my_list,int(len(my_list)/2))\n",
    "               else:\n",
    "                   random_elements=random.sample(my_list, k=min(avg,len(my_list)))\n",
    "               select=select+random_elements\n",
    "            if len(select)>=maxlen:\n",
    "                select=select[0:maxlen]\n",
    "            else:\n",
    "                select=select+select[0:maxlen-len(select)]\n",
    "            user_select.append(select)\n",
    "            \n",
    "        user_select=torch.tensor(user_select)\n",
    "\n",
    "        return user_select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dic=[]\n",
    "import math\n",
    "num=[]\n",
    "ma=[]\n",
    "def category_aggregation(edges):\n",
    "        return {'c': edges.src['category'], 'm': edges.src['h']}\n",
    "def sub_reduction_item_user(nodes):\n",
    "        # -1 indicate user-> node, which does not include category information\n",
    "        mail = nodes.mailbox['m']\n",
    "        batch_size, neighbor_size, feature_size = mail.shape\n",
    "                  \n",
    "    \n",
    "        # if (-1 in nodes.mailbox['c']) or nodes.mailbox['m'].shape[1] <=20:\n",
    "            \n",
    "        #     mail=mail.sum(dim=1)\n",
    "        # else:\n",
    "        #     neighbors = submodular_selection_feature(nodes)     \n",
    "        #     mail = mail[torch.arange(batch_size, dtype = torch.long, device = mail.device).unsqueeze(-1), neighbors]\n",
    "        #     mail=mail.sum(dim=1)\n",
    "        mail=mail.sum(dim=1)\n",
    "        return {'h': mail}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 7 but got size 8 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32md:\\code\\github\\MOERec\\test_main.ipynb 单元格 7\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mwith\u001b[39;00m graph\u001b[39m.\u001b[39mlocal_scope():\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/code/github/MOERec/test_main.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     graph\u001b[39m.\u001b[39;49mupdate_all(category_aggregation, sub_reduction_item_user, etype \u001b[39m=\u001b[39;49m etype)\n",
      "File \u001b[1;32mc:\\Users\\yuki_younai\\.conda\\envs\\PyTorch\\lib\\site-packages\\dgl\\heterograph.py:5110\u001b[0m, in \u001b[0;36mDGLGraph.update_all\u001b[1;34m(self, message_func, reduce_func, apply_node_func, etype)\u001b[0m\n\u001b[0;32m   5108\u001b[0m _, dtid \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_graph\u001b[39m.\u001b[39mmetagraph\u001b[39m.\u001b[39mfind_edge(etid)\n\u001b[0;32m   5109\u001b[0m g \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m etype \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m[etype]\n\u001b[1;32m-> 5110\u001b[0m ndata \u001b[39m=\u001b[39m core\u001b[39m.\u001b[39;49mmessage_passing(\n\u001b[0;32m   5111\u001b[0m     g, message_func, reduce_func, apply_node_func\n\u001b[0;32m   5112\u001b[0m )\n\u001b[0;32m   5113\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m   5114\u001b[0m     core\u001b[39m.\u001b[39mis_builtin(reduce_func)\n\u001b[0;32m   5115\u001b[0m     \u001b[39mand\u001b[39;00m reduce_func\u001b[39m.\u001b[39mname \u001b[39min\u001b[39;00m [\u001b[39m\"\u001b[39m\u001b[39mmin\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mmax\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   5116\u001b[0m     \u001b[39mand\u001b[39;00m ndata\n\u001b[0;32m   5117\u001b[0m ):\n\u001b[0;32m   5118\u001b[0m     \u001b[39m# Replace infinity with zero for isolated nodes\u001b[39;00m\n\u001b[0;32m   5119\u001b[0m     key \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(ndata\u001b[39m.\u001b[39mkeys())[\u001b[39m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\yuki_younai\\.conda\\envs\\PyTorch\\lib\\site-packages\\dgl\\core.py:405\u001b[0m, in \u001b[0;36mmessage_passing\u001b[1;34m(g, mfunc, rfunc, afunc)\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m         orig_nid \u001b[39m=\u001b[39m g\u001b[39m.\u001b[39mdstdata\u001b[39m.\u001b[39mget(NID, \u001b[39mNone\u001b[39;00m)\n\u001b[1;32m--> 405\u001b[0m         ndata \u001b[39m=\u001b[39m invoke_udf_reduce(g, rfunc, msgdata, orig_nid\u001b[39m=\u001b[39;49morig_nid)\n\u001b[0;32m    406\u001b[0m \u001b[39m# apply phase\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \u001b[39mif\u001b[39;00m afunc \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\yuki_younai\\.conda\\envs\\PyTorch\\lib\\site-packages\\dgl\\core.py:170\u001b[0m, in \u001b[0;36minvoke_udf_reduce\u001b[1;34m(graph, func, msgdata, orig_nid)\u001b[0m\n\u001b[0;32m    168\u001b[0m merged_rst \u001b[39m=\u001b[39m {}\n\u001b[0;32m    169\u001b[0m \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m bkt_rsts[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m--> 170\u001b[0m     merged_rst[k] \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39;49mcat([rst[k] \u001b[39mfor\u001b[39;49;00m rst \u001b[39min\u001b[39;49;00m bkt_rsts], dim\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[0;32m    171\u001b[0m merged_nodes \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcat(bkt_nodes, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[0;32m    172\u001b[0m retf\u001b[39m.\u001b[39mupdate_row(merged_nodes, merged_rst)\n",
      "File \u001b[1;32mc:\\Users\\yuki_younai\\.conda\\envs\\PyTorch\\lib\\site-packages\\dgl\\backend\\pytorch\\tensor.py:222\u001b[0m, in \u001b[0;36mcat\u001b[1;34m(seq, dim)\u001b[0m\n\u001b[0;32m    221\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcat\u001b[39m(seq, dim):\n\u001b[1;32m--> 222\u001b[0m     \u001b[39mreturn\u001b[39;00m th\u001b[39m.\u001b[39;49mcat(seq, dim\u001b[39m=\u001b[39;49mdim)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 0. Expected size 7 but got size 8 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "with graph.local_scope():\n",
    "    graph.update_all(category_aggregation, sub_reduction_item_user, etype = etype)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
